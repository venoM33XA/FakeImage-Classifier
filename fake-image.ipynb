{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726},{"sourceId":300340,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":256556,"modelId":277881}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''prompt = \"frog sitting in a forest\"\n\n# Generate image\nimage = pipe(prompt).images[0]'''\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''image.save(\"fake_image2.png\")\nprint(\"Image saved as fake_image.png\")'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ESRGAN from here ","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/xinntao/ESRGAN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:19:06.583262Z","iopub.execute_input":"2025-06-03T18:19:06.583678Z","iopub.status.idle":"2025-06-03T18:19:09.087603Z","shell.execute_reply.started":"2025-06-03T18:19:06.583645Z","shell.execute_reply":"2025-06-03T18:19:09.086604Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'ESRGAN'...\nremote: Enumerating objects: 225, done.\u001b[K\nremote: Counting objects: 100% (49/49), done.\u001b[K\nremote: Compressing objects: 100% (8/8), done.\u001b[K\nremote: Total 225 (delta 43), reused 41 (delta 41), pack-reused 176 (from 1)\u001b[K\nReceiving objects: 100% (225/225), 24.86 MiB | 20.38 MiB/s, done.\nResolving deltas: 100% (86/86), done.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install seedir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:19:09.088893Z","iopub.execute_input":"2025-06-03T18:19:09.089232Z","iopub.status.idle":"2025-06-03T18:19:12.881965Z","shell.execute_reply.started":"2025-06-03T18:19:09.089200Z","shell.execute_reply":"2025-06-03T18:19:12.881146Z"}},"outputs":[{"name":"stdout","text":"Collecting seedir\n  Downloading seedir-0.5.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from seedir) (8.4.0)\nDownloading seedir-0.5.0-py3-none-any.whl (112 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: seedir\nSuccessfully installed seedir-0.5.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip install gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:19:12.883915Z","iopub.execute_input":"2025-06-03T18:19:12.884226Z","iopub.status.idle":"2025-06-03T18:19:16.150117Z","shell.execute_reply.started":"2025-06-03T18:19:12.884201Z","shell.execute_reply":"2025-06-03T18:19:16.148979Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.17.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2025.1.31)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n!gdown --id 1TPrz5QKd8DHHt1k8SRtm6tMiPjz_Qene","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:19:16.151689Z","iopub.execute_input":"2025-06-03T18:19:16.151944Z","iopub.status.idle":"2025-06-03T18:19:36.334683Z","shell.execute_reply.started":"2025-06-03T18:19:16.151922Z","shell.execute_reply":"2025-06-03T18:19:36.333821Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1TPrz5QKd8DHHt1k8SRtm6tMiPjz_Qene\nTo: /kaggle/working/RRDB_ESRGAN_x4.pth\n100%|██████████████████████████████████████| 66.9M/66.9M [00:05<00:00, 12.7MB/s]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!pip install opencv-python glob2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:19:36.335803Z","iopub.execute_input":"2025-06-03T18:19:36.336138Z","iopub.status.idle":"2025-06-03T18:19:39.667239Z","shell.execute_reply.started":"2025-06-03T18:19:36.336107Z","shell.execute_reply":"2025-06-03T18:19:39.666178Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (0.7)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import seedir as sd\nsd.seedir('./', style='emoji')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:19:39.668326Z","iopub.execute_input":"2025-06-03T18:19:39.668577Z","iopub.status.idle":"2025-06-03T18:19:39.751330Z","shell.execute_reply.started":"2025-06-03T18:19:39.668555Z","shell.execute_reply":"2025-06-03T18:19:39.750535Z"}},"outputs":[{"name":"stdout","text":"📁 working/\n├─📁 gemini_outputs_v2/\n├─📁 ESRGAN/\n│ ├─📁 LR/\n│ │ ├─📄 baboon.png\n│ │ └─📄 comic.png\n│ ├─📁 models/\n│ │ └─📄 README.md\n│ ├─📄 .gitignore\n│ ├─📄 net_interp.py\n│ ├─📄 LICENSE\n│ ├─📄 transer_RRDB_models.py\n│ ├─📄 README.md\n│ ├─📁 .git/\n│ │ ├─📄 index\n│ │ ├─📁 hooks/\n│ │ │ ├─📄 post-update.sample\n│ │ │ ├─📄 prepare-commit-msg.sample\n│ │ │ ├─📄 pre-rebase.sample\n│ │ │ ├─📄 pre-receive.sample\n│ │ │ ├─📄 commit-msg.sample\n│ │ │ ├─📄 pre-applypatch.sample\n│ │ │ ├─📄 pre-push.sample\n│ │ │ ├─📄 applypatch-msg.sample\n│ │ │ ├─📄 push-to-checkout.sample\n│ │ │ ├─📄 pre-commit.sample\n│ │ │ ├─📄 pre-merge-commit.sample\n│ │ │ ├─📄 fsmonitor-watchman.sample\n│ │ │ └─📄 update.sample\n│ │ ├─📁 objects/\n│ │ │ ├─📁 info/\n│ │ │ └─📁 pack/\n│ │ │   ├─📄 pack-c2f86ec02e5332cdb80dcac8c139fff32d3c7812.pack\n│ │ │   └─📄 pack-c2f86ec02e5332cdb80dcac8c139fff32d3c7812.idx\n│ │ ├─📄 config\n│ │ ├─📁 logs/\n│ │ │ ├─📄 HEAD\n│ │ │ └─📁 refs/\n│ │ │   ├─📁 heads/\n│ │ │   │ └─📄 master\n│ │ │   └─📁 remotes/\n│ │ │     └─📁 origin/\n│ │ │       └─📄 HEAD\n│ │ ├─📁 info/\n│ │ │ └─📄 exclude\n│ │ ├─📄 packed-refs\n│ │ ├─📁 branches/\n│ │ ├─📄 HEAD\n│ │ ├─📁 refs/\n│ │ │ ├─📁 heads/\n│ │ │ │ └─📄 master\n│ │ │ ├─📁 remotes/\n│ │ │ │ └─📁 origin/\n│ │ │ │   └─📄 HEAD\n│ │ │ └─📁 tags/\n│ │ └─📄 description\n│ ├─📄 test.py\n│ ├─📁 results/\n│ │ └─📄 baboon_ESRGAN.png\n│ ├─📄 QA.md\n│ ├─📁 figures/\n│ │ ├─📄 BN_artifacts.jpg\n│ │ ├─📄 RRDB.png\n│ │ ├─📄 patch_b.png\n│ │ ├─📄 qualitative_cmp_03.jpg\n│ │ ├─📄 qualitative_cmp_04.jpg\n│ │ ├─📄 qualitative_cmp_02.jpg\n│ │ ├─📄 train_deeper_neta.png\n│ │ ├─📄 43074.gif\n│ │ ├─📄 102061.gif\n│ │ ├─📄 architecture.jpg\n│ │ ├─📄 train_deeper_netb.png\n│ │ ├─📄 abalation_study.png\n│ │ ├─📄 net_interp.jpg\n│ │ ├─📄 baboon.jpg\n│ │ ├─📄 qualitative_cmp_01.jpg\n│ │ ├─📄 patch_a.png\n│ │ └─📄 81.gif\n│ └─📄 RRDBNet_arch.py\n├─📁 .virtual_documents/\n└─📄 RRDB_ESRGAN_x4.pth\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:19:39.752097Z","iopub.execute_input":"2025-06-03T18:19:39.752372Z","iopub.status.idle":"2025-06-03T18:19:43.145183Z","shell.execute_reply.started":"2025-06-03T18:19:39.752351Z","shell.execute_reply":"2025-06-03T18:19:43.144107Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import os, shutil\nsource = \"./RRDB_ESRGAN_x4.pth\"\ndestination = \"./ESRGAN/models/\"\nshutil.move(source,destination)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:19:43.148327Z","iopub.execute_input":"2025-06-03T18:19:43.148597Z","iopub.status.idle":"2025-06-03T18:19:43.155714Z","shell.execute_reply.started":"2025-06-03T18:19:43.148575Z","shell.execute_reply":"2025-06-03T18:19:43.154870Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'./ESRGAN/models/RRDB_ESRGAN_x4.pth'"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"!gdown --id 1sdB-k6-XHzN8WfAA51d8l1b7Q0TH9iBt\n!gdown --id 1JIlrwnID8-sb16DByx2vmnXIfCrFBOFb\n!gdown --id 1-dl-OtffdxzIgtYjZ8fQXkzkCNLEDSHu\n!gdown --id 1TAaSaVzf7Lfw6yT2ROuuiPSwnuCoYsRT\n!gdown --id 1v_9DWkmPVyBVR3Ax_OVepMhvmFXVsScT","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:19:43.157246Z","iopub.execute_input":"2025-06-03T18:19:43.157459Z","iopub.status.idle":"2025-06-03T18:20:12.001570Z","shell.execute_reply.started":"2025-06-03T18:19:43.157434Z","shell.execute_reply":"2025-06-03T18:20:12.000245Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1sdB-k6-XHzN8WfAA51d8l1b7Q0TH9iBt\nTo: /kaggle/working/horse.jpg\n100%|██████████████████████████████████████| 5.40k/5.40k [00:00<00:00, 20.2MB/s]\n/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1JIlrwnID8-sb16DByx2vmnXIfCrFBOFb\nTo: /kaggle/working/image2.jpg\n100%|███████████████████████████████████████| 53.2k/53.2k [00:00<00:00, 640kB/s]\n/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1-dl-OtffdxzIgtYjZ8fQXkzkCNLEDSHu\nTo: /kaggle/working/img3.jpg\n100%|█████████████████████████████████████████| 106k/106k [00:00<00:00, 797kB/s]\n/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1TAaSaVzf7Lfw6yT2ROuuiPSwnuCoYsRT\nTo: /kaggle/working/img5.jpg\n100%|██████████████████████████████████████| 32.2k/32.2k [00:00<00:00, 4.79MB/s]\n/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1v_9DWkmPVyBVR3Ax_OVepMhvmFXVsScT\nTo: /kaggle/working/img6.jpg\n100%|███████████████████████████████████████| 89.0k/89.0k [00:00<00:00, 729kB/s]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#moving these images under the LR folder\nj=0\nfor i in os.listdir(\"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE/\"):\n    if(j>20):\n        break\n       \n    source = f\"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE/{i}\"\n    destination = \"./ESRGAN/LR/\"\n    shutil.copy(source,destination)\n    j+=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:12.002708Z","iopub.execute_input":"2025-06-03T18:20:12.003124Z","iopub.status.idle":"2025-06-03T18:20:12.624315Z","shell.execute_reply.started":"2025-06-03T18:20:12.003084Z","shell.execute_reply":"2025-06-03T18:20:12.623381Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"source = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE/1000 (10).jpg\"\ndestination = \"./ESRGAN/LR/\"\nshutil.copy(source,destination)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:12.625161Z","iopub.execute_input":"2025-06-03T18:20:12.625387Z","iopub.status.idle":"2025-06-03T18:20:12.637538Z","shell.execute_reply.started":"2025-06-03T18:20:12.625368Z","shell.execute_reply":"2025-06-03T18:20:12.636818Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'./ESRGAN/LR/1000 (10).jpg'"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"\n%cd ESRGAN\n!python test.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:12.638451Z","iopub.execute_input":"2025-06-03T18:20:12.638748Z","iopub.status.idle":"2025-06-03T18:20:19.092052Z","shell.execute_reply.started":"2025-06-03T18:20:12.638718Z","shell.execute_reply":"2025-06-03T18:20:19.091133Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ESRGAN\n/kaggle/working/ESRGAN/test.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path), strict=True)\nModel path models/RRDB_ESRGAN_x4.pth. \nTesting...\n1 4223 (6)\n2 2052 (3)\n3 5194 (5)\n4 3263 (8)\n5 3028 (2)\n6 5387 (6)\n7 4609 (9)\n8 2459 (10)\n9 baboon\n10 4851 (5)\n11 4326 (9)\n12 2270 (7)\n13 4795 (2)\n14 5842 (2)\n15 1000 (10)\n16 3831 (9)\n17 comic\n18 5685 (8)\n19 5183 (2)\n20 3825 (3)\n21 4131 (5)\n22 4093 (7)\n23 5357 (8)\n24 1438 (6)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"\n%cd /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:19.093265Z","iopub.execute_input":"2025-06-03T18:20:19.093649Z","iopub.status.idle":"2025-06-03T18:20:19.099665Z","shell.execute_reply.started":"2025-06-03T18:20:19.093616Z","shell.execute_reply":"2025-06-03T18:20:19.098785Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import seedir as sd\nsd.seedir('./', style='emoji')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:19.100599Z","iopub.execute_input":"2025-06-03T18:20:19.100920Z","iopub.status.idle":"2025-06-03T18:20:19.123083Z","shell.execute_reply.started":"2025-06-03T18:20:19.100888Z","shell.execute_reply":"2025-06-03T18:20:19.122392Z"}},"outputs":[{"name":"stdout","text":"📁 working/\n├─📄 img6.jpg\n├─📄 img3.jpg\n├─📄 horse.jpg\n├─📁 gemini_outputs_v2/\n├─📄 image2.jpg\n├─📄 img5.jpg\n├─📁 ESRGAN/\n│ ├─📁 LR/\n│ │ ├─📄 4223 (6).jpg\n│ │ ├─📄 2052 (3).jpg\n│ │ ├─📄 5194 (5).jpg\n│ │ ├─📄 3263 (8).jpg\n│ │ ├─📄 3028 (2).jpg\n│ │ ├─📄 5387 (6).jpg\n│ │ ├─📄 4609 (9).jpg\n│ │ ├─📄 2459 (10).jpg\n│ │ ├─📄 baboon.png\n│ │ ├─📄 4851 (5).jpg\n│ │ ├─📄 4326 (9).jpg\n│ │ ├─📄 2270 (7).jpg\n│ │ ├─📄 4795 (2).jpg\n│ │ ├─📄 5842 (2).jpg\n│ │ ├─📄 1000 (10).jpg\n│ │ ├─📄 3831 (9).jpg\n│ │ ├─📄 comic.png\n│ │ ├─📄 5685 (8).jpg\n│ │ ├─📄 5183 (2).jpg\n│ │ ├─📄 3825 (3).jpg\n│ │ ├─📄 4131 (5).jpg\n│ │ ├─📄 4093 (7).jpg\n│ │ ├─📄 5357 (8).jpg\n│ │ └─📄 1438 (6).jpg\n│ ├─📁 __pycache__/\n│ │ └─📄 RRDBNet_arch.cpython-310.pyc\n│ ├─📁 models/\n│ │ ├─📄 README.md\n│ │ └─📄 RRDB_ESRGAN_x4.pth\n│ ├─📄 .gitignore\n│ ├─📄 net_interp.py\n│ ├─📄 LICENSE\n│ ├─📄 transer_RRDB_models.py\n│ ├─📄 README.md\n│ ├─📁 .git/\n│ │ ├─📄 index\n│ │ ├─📁 hooks/\n│ │ │ ├─📄 post-update.sample\n│ │ │ ├─📄 prepare-commit-msg.sample\n│ │ │ ├─📄 pre-rebase.sample\n│ │ │ ├─📄 pre-receive.sample\n│ │ │ ├─📄 commit-msg.sample\n│ │ │ ├─📄 pre-applypatch.sample\n│ │ │ ├─📄 pre-push.sample\n│ │ │ ├─📄 applypatch-msg.sample\n│ │ │ ├─📄 push-to-checkout.sample\n│ │ │ ├─📄 pre-commit.sample\n│ │ │ ├─📄 pre-merge-commit.sample\n│ │ │ ├─📄 fsmonitor-watchman.sample\n│ │ │ └─📄 update.sample\n│ │ ├─📁 objects/\n│ │ │ ├─📁 info/\n│ │ │ └─📁 pack/\n│ │ │   ├─📄 pack-c2f86ec02e5332cdb80dcac8c139fff32d3c7812.pack\n│ │ │   └─📄 pack-c2f86ec02e5332cdb80dcac8c139fff32d3c7812.idx\n│ │ ├─📄 config\n│ │ ├─📁 logs/\n│ │ │ ├─📄 HEAD\n│ │ │ └─📁 refs/\n│ │ │   ├─📁 heads/\n│ │ │   │ └─📄 master\n│ │ │   └─📁 remotes/\n│ │ │     └─📁 origin/\n│ │ │       └─📄 HEAD\n│ │ ├─📁 info/\n│ │ │ └─📄 exclude\n│ │ ├─📄 packed-refs\n│ │ ├─📁 branches/\n│ │ ├─📄 HEAD\n│ │ ├─📁 refs/\n│ │ │ ├─📁 heads/\n│ │ │ │ └─📄 master\n│ │ │ ├─📁 remotes/\n│ │ │ │ └─📁 origin/\n│ │ │ │   └─📄 HEAD\n│ │ │ └─📁 tags/\n│ │ └─📄 description\n│ ├─📄 test.py\n│ ├─📁 results/\n│ │ ├─📄 5183 (2)_rlt.png\n│ │ ├─📄 1438 (6)_rlt.png\n│ │ ├─📄 5685 (8)_rlt.png\n│ │ ├─📄 comic_rlt.png\n│ │ ├─📄 5842 (2)_rlt.png\n│ │ ├─📄 baboon_ESRGAN.png\n│ │ ├─📄 4131 (5)_rlt.png\n│ │ ├─📄 2052 (3)_rlt.png\n│ │ ├─📄 2270 (7)_rlt.png\n│ │ ├─📄 5357 (8)_rlt.png\n│ │ ├─📄 2459 (10)_rlt.png\n│ │ ├─📄 1000 (10)_rlt.png\n│ │ ├─📄 4223 (6)_rlt.png\n│ │ ├─📄 5194 (5)_rlt.png\n│ │ ├─📄 4851 (5)_rlt.png\n│ │ ├─📄 5387 (6)_rlt.png\n│ │ ├─📄 3028 (2)_rlt.png\n│ │ ├─📄 baboon_rlt.png\n│ │ ├─📄 3831 (9)_rlt.png\n│ │ ├─📄 3825 (3)_rlt.png\n│ │ ├─📄 4326 (9)_rlt.png\n│ │ ├─📄 4093 (7)_rlt.png\n│ │ ├─📄 4609 (9)_rlt.png\n│ │ ├─📄 4795 (2)_rlt.png\n│ │ └─📄 3263 (8)_rlt.png\n│ ├─📄 QA.md\n│ ├─📁 figures/\n│ │ ├─📄 BN_artifacts.jpg\n│ │ ├─📄 RRDB.png\n│ │ ├─📄 patch_b.png\n│ │ ├─📄 qualitative_cmp_03.jpg\n│ │ ├─📄 qualitative_cmp_04.jpg\n│ │ ├─📄 qualitative_cmp_02.jpg\n│ │ ├─📄 train_deeper_neta.png\n│ │ ├─📄 43074.gif\n│ │ ├─📄 102061.gif\n│ │ ├─📄 architecture.jpg\n│ │ ├─📄 train_deeper_netb.png\n│ │ ├─📄 abalation_study.png\n│ │ ├─📄 net_interp.jpg\n│ │ ├─📄 baboon.jpg\n│ │ ├─📄 qualitative_cmp_01.jpg\n│ │ ├─📄 patch_a.png\n│ │ └─📄 81.gif\n│ └─📄 RRDBNet_arch.py\n└─📁 .virtual_documents/\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"gemini_api_key ='AIzaSyA6_Du4pJtYbXhEbMc3xIoyiLoC02i1lAg'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:19.123766Z","iopub.execute_input":"2025-06-03T18:20:19.123946Z","iopub.status.idle":"2025-06-03T18:20:19.127516Z","shell.execute_reply.started":"2025-06-03T18:20:19.123929Z","shell.execute_reply":"2025-06-03T18:20:19.126540Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import google.generativeai as genai\nfrom PIL import Image\n\n# Load API Key (Replace with your actual API key)\ngenai.configure(api_key=gemini_api_key)\n\n# Load Gemini Vision model\nmodel = genai.GenerativeModel(\"gemini-1.5-flash\")\n\n# Load the image\n'''image_path = f\"/kaggle/working/ESRGAN/results/4599 (6)_rlt.png\"\nimage = Image.open(image_path)\n\n# Send the image to Gemini for analysis\nresponse = model.generate_content([image, prompt])\nprint(response.text)'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:19.128241Z","iopub.execute_input":"2025-06-03T18:20:19.128454Z","iopub.status.idle":"2025-06-03T18:20:19.142603Z","shell.execute_reply.started":"2025-06-03T18:20:19.128420Z","shell.execute_reply":"2025-06-03T18:20:19.141959Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'image_path = f\"/kaggle/working/ESRGAN/results/4599 (6)_rlt.png\"\\nimage = Image.open(image_path)\\n\\n# Send the image to Gemini for analysis\\nresponse = model.generate_content([image, prompt])\\nprint(response.text)'"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:19.143539Z","iopub.execute_input":"2025-06-03T18:20:19.143761Z","iopub.status.idle":"2025-06-03T18:20:26.102119Z","shell.execute_reply.started":"2025-06-03T18:20:19.143743Z","shell.execute_reply":"2025-06-03T18:20:26.101179Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nmodel = timm.create_model(\"tiny_vit_21m_224.dist_in22k\", pretrained=True)\nmodel.head.fc = nn.Linear(model.head.fc.in_features, 1)\nimport os\n\nif not os.path.exists(\"/kaggle/input/tiny_vit_4000/pytorch/default/1/tiny_vit_modified.pth\"):\n    print(\"Error: model2.pth not found!\")\n\nmodel.load_state_dict(torch.load(\"/kaggle/input/tiny_vit_4000/pytorch/default/1/tiny_vit_modified.pth\"))\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:26.102964Z","iopub.execute_input":"2025-06-03T18:20:26.103295Z","iopub.status.idle":"2025-06-03T18:20:28.425948Z","shell.execute_reply.started":"2025-06-03T18:20:26.103264Z","shell.execute_reply":"2025-06-03T18:20:28.425277Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98cc4da03c5041a696bc5b569fcffb23"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"data_config = timm.data.resolve_model_data_config(model)\ntest_transforms = timm.data.create_transform(**data_config, is_training=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:28.426726Z","iopub.execute_input":"2025-06-03T18:20:28.427015Z","iopub.status.idle":"2025-06-03T18:20:28.431176Z","shell.execute_reply.started":"2025-06-03T18:20:28.426987Z","shell.execute_reply":"2025-06-03T18:20:28.430261Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"class GradCAM:\n    def __init__(self, model, target_layer_name):\n        self.model = model\n        self.target_layer_name = target_layer_name\n        self.gradients = None\n        self.activations = None\n        self._register_hooks()\n\n    def _register_hooks(self):\n        target_layer = dict(self.model.named_modules())[self.target_layer_name]\n\n        def forward_hook(module, input, output):\n            self.activations = output\n\n        def backward_hook(module, grad_input, grad_output):\n            self.gradients = grad_output[0]\n\n        target_layer.register_forward_hook(forward_hook)\n        target_layer.register_full_backward_hook(backward_hook)\n\n    def generate(self, input_tensor, class_idx=None):\n        self.model.eval()\n        output = self.model(input_tensor)\n\n        if class_idx is None:\n            class_idx = output.argmax(dim=1).item()\n\n        # Backpropagate\n        self.model.zero_grad()\n        output[:, class_idx].backward(retain_graph=True)\n\n        # Compute Grad-CAM\n        gradients = self.gradients.cpu().detach()\n        activations = self.activations.cpu().detach()\n\n        weights = gradients.mean(dim=(2, 3), keepdim=True)\n        grad_cam = torch.sum(weights * activations, dim=1).squeeze()\n        grad_cam = F.relu(grad_cam)\n\n        # Normalize the Grad-CAM output\n        grad_cam -= grad_cam.min()\n        grad_cam /= grad_cam.max()\n        return grad_cam.numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:28.432118Z","iopub.execute_input":"2025-06-03T18:20:28.432388Z","iopub.status.idle":"2025-06-03T18:20:28.446239Z","shell.execute_reply.started":"2025-06-03T18:20:28.432355Z","shell.execute_reply":"2025-06-03T18:20:28.445575Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"\n\ndef gradcam(image, grad_cam, alpha=0.5, cmap=\"jet\"):\n    grad_cam_resized = (\n        F.interpolate(\n            torch.tensor(grad_cam).unsqueeze(0).unsqueeze(0),\n            size=image.shape[:2],\n            mode=\"bilinear\",\n            align_corners=False,\n        )\n        .squeeze()\n        .numpy()\n    )\n\n    heatmap = plt.get_cmap(cmap)(grad_cam_resized)[..., :3]\n    heatmap = (heatmap * 255).astype(np.uint8)\n\n    return heatmap\n\n\n# Grad-CAM for high-level feature map\ntarget_layer = \"stages.3.blocks.1.local_conv\"\ngrad_cam = GradCAM(model, target_layer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:28.446961Z","iopub.execute_input":"2025-06-03T18:20:28.447197Z","iopub.status.idle":"2025-06-03T18:20:28.461020Z","shell.execute_reply.started":"2025-06-03T18:20:28.447179Z","shell.execute_reply":"2025-06-03T18:20:28.460317Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"\ndef merge_original_and_gradcam(\n    original_img_path, gradcam_output, alpha=0.5, cmap=\"jet\"\n):\n    original_img = cv2.imread(original_img_path)\n    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n\n    gradcam_resized = cv2.resize(\n        gradcam_output, (original_img.shape[1], original_img.shape[0])\n    )\n\n    gradcam_resized = (gradcam_resized * 255).astype(np.uint8)\n\n    heatmap = cv2.applyColorMap(gradcam_resized, cv2.COLORMAP_JET)\n    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n\n    overlay = cv2.addWeighted(original_img, 1 - alpha, heatmap, alpha, 0)\n    return overlay\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:28.461853Z","iopub.execute_input":"2025-06-03T18:20:28.462165Z","iopub.status.idle":"2025-06-03T18:20:28.476824Z","shell.execute_reply.started":"2025-06-03T18:20:28.462145Z","shell.execute_reply":"2025-06-03T18:20:28.476038Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"dir_path = \"/kaggle/working/gradcam_images\"\ni=0\n# Create the directory if it doesn't exist\nos.makedirs(dir_path, exist_ok=True)\nfor img in tqdm(os.listdir(\"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE\")):\n  if(i<=20):\n    img_path = os.path.join(\"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE\", img)\n    image = Image.open(img_path).convert(\"RGB\")\n    image = test_transforms(image).unsqueeze(0).to(device)\n\n    grad_cam_output = grad_cam.generate(image)\n    image = plt.imread(img_path)\n    grad_cam_output = gradcam(image, grad_cam_output)\n    overlay = merge_original_and_gradcam(img_path, grad_cam_output)\n\n    plt.imsave(f\"gradcam_images/{img}\", overlay)\n    i+=1\n  else:\n      break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:28.480741Z","iopub.execute_input":"2025-06-03T18:20:28.480932Z","iopub.status.idle":"2025-06-03T18:20:30.204171Z","shell.execute_reply.started":"2025-06-03T18:20:28.480915Z","shell.execute_reply":"2025-06-03T18:20:30.203297Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 21/50000 [00:01<1:07:13, 12.39it/s]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"\nprompt = \"\"\" Analyze the provided image and its corresponding Grad-CAM output generated by a model trained to detect fake visuals. Identify and explain artifacts that indicate it is fake. Focus primarily on the original image to identify and explain distinguishing artifacts that indicate it is fake. Use the Grad-CAM output for reference only when necessary. Provide clear, concise explanations (maximum 50 words each) using the specified artifacts below. Include positional references like 'top left' or 'bottom right' when relevant. DO NOT include any other sentences or artifacts in your response. Select only 6-7 relevant artifacts.\nOutput Format:\nWrite each artifact and explanation on a separate line, using the format:\nArtifact Name: Explanation.\nFor example:\nUnrealistic eye reflections: Unnatural symmetrical light reflections in both eyes, suggesting generated elements.\nOver-smoothing of natural textures: Fur appears unusually smooth in the top right, lacking natural texture variation.\n\nNotes:\nExplanations should remain under 50 words for clarity.\nAVOID referencing artifacts not listed or including extra commentary.\n\"\"\"  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:30.205808Z","iopub.execute_input":"2025-06-03T18:20:30.206045Z","iopub.status.idle":"2025-06-03T18:20:30.210019Z","shell.execute_reply.started":"2025-06-03T18:20:30.206025Z","shell.execute_reply":"2025-06-03T18:20:30.209118Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"import google.generativeai as genai\nfrom PIL import Image\nimport os\nimport glob\nimport re  # To remove \"_rlt\"\nimport time \n\nmodel = genai.GenerativeModel(\"gemini-1.5-flash\")\n\n# Define paths\nesrgan_folder = \"/kaggle/working/ESRGAN/results/\"\ngradcam_folder = \"/kaggle/working/gradcam_images/\"\noutput_folder = \"/kaggle/working/gemini_outputs_v2/\"  # NEW folder\n\n# Ensure output folder exists\nos.makedirs(output_folder, exist_ok=True)\n\n# Get all ESRGAN image paths\nesrgan_images = glob.glob(os.path.join(esrgan_folder, \"*.png\"))  # Adjust extension if needed\n\nprocessed_count = 0\nmax_pairs = 10  # Process only 10 image pairs\n\n# Process only ESRGAN images that have a matching Grad-CAM image\nfor esrgan_path in esrgan_images:\n    if processed_count >= max_pairs:\n        break\n\n    filename = os.path.basename(esrgan_path)  # e.g., \"4599 (6)_rlt.png\"\n    base_name = os.path.splitext(filename)[0]  # Remove .png, e.g., \"4599 (6)_rlt\"\n\n    # Remove \"_rlt\" if present\n    clean_name = re.sub(r\"_rlt$\", \"\", base_name)  # e.g., \"4599 (6)\"\n\n    # Find corresponding Grad-CAM image\n    gradcam_path = os.path.join(gradcam_folder, f\"{clean_name}.jpg\")  # Adjust extension if needed\n\n    # Skip ESRGAN image if no matching Grad-CAM image\n    if not os.path.exists(gradcam_path):\n        print(f\"Skipping {filename}: No corresponding Grad-CAM image found.\")\n        continue\n\n    # Load images\n    image1 = Image.open(esrgan_path)\n    image2 = Image.open(gradcam_path)\n\n    # Make sure 'prompt' is defined before this loop!\n    response = model.generate_content([image1, image2, prompt])\n\n    # Save output to a text file (use clean name)\n    output_path = os.path.join(output_folder, f\"{clean_name}.txt\")\n    with open(output_path, \"w\") as f:\n        f.write(response.text)\n\n    print(f\"Processed {filename} -> Output saved to {output_path}\")\n    processed_count += 1\n    time.sleep(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:30.210916Z","iopub.execute_input":"2025-06-03T18:20:30.211180Z","iopub.status.idle":"2025-06-03T18:21:51.009028Z","shell.execute_reply.started":"2025-06-03T18:20:30.211158Z","shell.execute_reply":"2025-06-03T18:21:51.007950Z"}},"outputs":[{"name":"stdout","text":"Processed 5183 (2)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/5183 (2).txt\nProcessed 1438 (6)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/1438 (6).txt\nProcessed 5685 (8)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/5685 (8).txt\nSkipping comic_rlt.png: No corresponding Grad-CAM image found.\nProcessed 5842 (2)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/5842 (2).txt\nSkipping baboon_ESRGAN.png: No corresponding Grad-CAM image found.\nProcessed 4131 (5)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/4131 (5).txt\nProcessed 2052 (3)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/2052 (3).txt\nProcessed 2270 (7)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/2270 (7).txt\nProcessed 5357 (8)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/5357 (8).txt\nProcessed 2459 (10)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/2459 (10).txt\nSkipping 1000 (10)_rlt.png: No corresponding Grad-CAM image found.\nProcessed 4223 (6)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/4223 (6).txt\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import google.generativeai as genai\nfrom PIL import Image\nimport os\nimport glob\nimport re  # To remove \"_rlt\"\n\nmodel = genai.GenerativeModel(\"gemini-1.5-flash\")\n\n# Define paths\nesrgan_folder = \"/kaggle/working/ESRGAN/results/\"\ngradcam_folder = \"/kaggle/working/gradcam_images/\"\noutput_folder = \"/kaggle/working/gemini_outputs_v2/\"  # NEW folder\n\n# Ensure output folder exists\nos.makedirs(output_folder, exist_ok=True)\n\n# Get all ESRGAN image paths\nesrgan_images = glob.glob(os.path.join(esrgan_folder, \"*.png\"))  # Adjust extension if needed\n\nstart_index = 10    # Skip first 10 processed pairs\nmax_pairs = 10     # Process next 10 pairs\n\ncount = 0           # Number of pairs processed in this run\nskipped = 0         # Number of valid pairs skipped (to reach start_index)\n\nfor esrgan_path in esrgan_images:\n    filename = os.path.basename(esrgan_path)\n    base_name = os.path.splitext(filename)[0]\n    clean_name = re.sub(r\"_rlt$\", \"\", base_name)\n\n    gradcam_path = os.path.join(gradcam_folder, f\"{clean_name}.jpg\")\n    if not os.path.exists(gradcam_path):\n        print(f\"Skipping {filename}: No corresponding Grad-CAM image found.\")\n        continue\n\n    if skipped < start_index:\n        skipped += 1\n        continue\n\n    if count >= max_pairs:\n        break\n\n    image1 = Image.open(esrgan_path)\n    image2 = Image.open(gradcam_path)\n\n    # Make sure 'prompt' is defined before this loop!\n    response = model.generate_content([image1, image2, prompt])\n\n    output_path = os.path.join(output_folder, f\"{clean_name}.txt\")\n    with open(output_path, \"w\") as f:\n        f.write(response.text)\n\n    print(f\"Processed {filename} -> Output saved to {output_path}\")\n    count += 1\n    time.sleep(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:21:51.009921Z","iopub.execute_input":"2025-06-03T18:21:51.010186Z","iopub.status.idle":"2025-06-03T18:23:20.130501Z","shell.execute_reply.started":"2025-06-03T18:21:51.010166Z","shell.execute_reply":"2025-06-03T18:23:20.129481Z"}},"outputs":[{"name":"stdout","text":"Skipping comic_rlt.png: No corresponding Grad-CAM image found.\nSkipping baboon_ESRGAN.png: No corresponding Grad-CAM image found.\nSkipping 1000 (10)_rlt.png: No corresponding Grad-CAM image found.\nProcessed 5194 (5)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/5194 (5).txt\nProcessed 4851 (5)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/4851 (5).txt\nProcessed 5387 (6)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/5387 (6).txt\nProcessed 3028 (2)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/3028 (2).txt\nSkipping baboon_rlt.png: No corresponding Grad-CAM image found.\nProcessed 3831 (9)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/3831 (9).txt\nProcessed 3825 (3)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/3825 (3).txt\nProcessed 4326 (9)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/4326 (9).txt\nProcessed 4093 (7)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/4093 (7).txt\nProcessed 4609 (9)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/4609 (9).txt\nProcessed 4795 (2)_rlt.png -> Output saved to /kaggle/working/gemini_outputs_v2/4795 (2).txt\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:23:20.131385Z","iopub.execute_input":"2025-06-03T18:23:20.131606Z","iopub.status.idle":"2025-06-03T18:23:20.135140Z","shell.execute_reply.started":"2025-06-03T18:23:20.131587Z","shell.execute_reply":"2025-06-03T18:23:20.134351Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"images1_dir = \"/kaggle/working/ESRGAN/results\"\nimages2_dir = \"/kaggle/working/gradcam_images\"\ntexts_dir = \"/kaggle/working/gemini_outputs\"\n\ndef clean_filename(filename):\n    filename = os.path.splitext(filename)[0]  # Remove file extension\n    filename = re.sub(r\"_rlt$\", \"\", filename)  # Remove \"_rlt\" if present at the end\n    return filename\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:23:20.135814Z","iopub.execute_input":"2025-06-03T18:23:20.135997Z","iopub.status.idle":"2025-06-03T18:23:20.150495Z","shell.execute_reply.started":"2025-06-03T18:23:20.135980Z","shell.execute_reply":"2025-06-03T18:23:20.149760Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"import os\nimport json\nimport base64\nimport re\n\n# Define directories\nimages1_dir = \"/kaggle/working/ESRGAN/results\"\nimages2_dir = \"/kaggle/working/gradcam_images\"\ntexts_dir = \"/kaggle/working/gemini_outputs_v2\"\noutput_file = \"/kaggle/working/dataset_qwen.jsonl\"\n\n# Encode image to base64 (optional, if needed)\ndef encode_image(image_path):\n    with open(image_path, \"rb\") as image_file:\n        encoded = base64.b64encode(image_file.read()).decode(\"utf-8\")\n        ext = os.path.splitext(image_path)[1].lower()\n        mime = \"image/png\" if ext == \".png\" else \"image/jpeg\"\n        return f\"data:{mime};base64,{encoded}\"\n\n# Clean filename to match\ndef clean_filename(filename):\n    filename = os.path.splitext(filename)[0]\n    return re.sub(r\"_rlt$\", \"\", filename)\n\n# Process\ndataset = []\nimage_filenames = sorted(os.listdir(images1_dir))\n\nfor filename in image_filenames:\n    base_name = clean_filename(filename)\n\n    img1_path = os.path.join(images1_dir, filename)\n    img2_path = os.path.join(images2_dir, base_name + \".jpg\")\n    text_path = os.path.join(texts_dir, base_name + \".txt\")\n\n    if not (os.path.exists(img1_path) and os.path.exists(img2_path) and os.path.exists(text_path)):\n        print(f\"Skipping: {base_name} due to missing file\")\n        continue\n\n    with open(text_path, \"r\", encoding=\"utf-8\") as file:\n        label = file.read().strip()\n\n    # Construct prompt text (customize this based on your use case)\n   # prompt = \"Please analyze the differences between the two images and explain your reasoning.\"\n\n    # Format for Qwen\n    entry = {\n        \"messages\": [\n            {\n                \"content\": f\"<image><image>{prompt}\",\n                \"role\": \"user\",\n            },\n            {\n                \"content\": label,\n                \"role\": \"assistant\"\n            }\n        ],\n        \"images\": [img1_path, img2_path]\n    }\n\n    dataset.append(entry)\n\n# Write to JSONL\nwith open(output_file, \"w\", encoding=\"utf-8\") as f:\n    for entry in dataset:\n        f.write(json.dumps(entry) + \"\\n\")\n\nprint(f\"✅ Dataset for Qwen saved to {output_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:23:20.151312Z","iopub.execute_input":"2025-06-03T18:23:20.151533Z","iopub.status.idle":"2025-06-03T18:23:20.171771Z","shell.execute_reply.started":"2025-06-03T18:23:20.151512Z","shell.execute_reply":"2025-06-03T18:23:20.170735Z"}},"outputs":[{"name":"stdout","text":"Skipping: 1000 (10) due to missing file\nSkipping: 3263 (8) due to missing file\nSkipping: baboon_ESRGAN due to missing file\nSkipping: baboon due to missing file\nSkipping: comic due to missing file\n✅ Dataset for Qwen saved to /kaggle/working/dataset_qwen.jsonl\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"!pip install transformers accelerate peft datasets torch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:23:20.172768Z","iopub.execute_input":"2025-06-03T18:23:20.173062Z","iopub.status.idle":"2025-06-03T18:23:24.143152Z","shell.execute_reply.started":"2025-06-03T18:23:20.173027Z","shell.execute_reply":"2025-06-03T18:23:24.142038Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"# data json prep till here ","metadata":{}},{"cell_type":"code","source":"import base64\nfrom PIL import Image\nfrom io import BytesIO\n\ndef decode_base64_to_image(b64_string):\n    # Handle possible data URI format\n    if b64_string.startswith(\"data:image\"):\n        b64_string = b64_string.split(\",\", 1)[1]\n    image_data = base64.b64decode(b64_string)\n    return Image.open(BytesIO(image_data)).convert(\"RGB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:23:24.144516Z","iopub.execute_input":"2025-06-03T18:23:24.144886Z","iopub.status.idle":"2025-06-03T18:23:24.150231Z","shell.execute_reply.started":"2025-06-03T18:23:24.144845Z","shell.execute_reply":"2025-06-03T18:23:24.149266Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"# model config ","metadata":{}},{"cell_type":"code","source":"pip install transformers_stream_generator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:23:24.151136Z","iopub.execute_input":"2025-06-03T18:23:24.151358Z","iopub.status.idle":"2025-06-03T18:23:32.306127Z","shell.execute_reply.started":"2025-06-03T18:23:24.151339Z","shell.execute_reply":"2025-06-03T18:23:32.304851Z"}},"outputs":[{"name":"stdout","text":"Collecting transformers_stream_generator\n  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: transformers>=4.26.1 in /usr/local/lib/python3.10/dist-packages (from transformers_stream_generator) (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers>=4.26.1->transformers_stream_generator) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers>=4.26.1->transformers_stream_generator) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2024.2.0)\nBuilding wheels for collected packages: transformers_stream_generator\n  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12425 sha256=0b6bb1858badc0ffaffead28bb6038fa73e7043559f5fe776d7454684eb0066f\n  Stored in directory: /root/.cache/pip/wheels/95/4a/90/140f7b67d125906f6a165f38aad212ecb4a695ad0d87582437\nSuccessfully built transformers_stream_generator\nInstalling collected packages: transformers_stream_generator\nSuccessfully installed transformers_stream_generator-0.0.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"from transformers import AutoProcessor, AutoTokenizer, AutoModelForVision2Seq\nimport torch\n\nmodel_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n\n# Load the tokenizer and processor\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\nprocessor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n\n# Load the vision-language model\nmodel = AutoModelForVision2Seq.from_pretrained(\n    model_name,\n    trust_remote_code=True,\n    device_map=\"auto\",  # or 'cuda:0' if you're only using one GPU\n    torch_dtype=torch.float16\n)\n\n# ✅ Ensure pad_token is set\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = \"<|endoftext|>\"\n\n# ✅ Print pad token info\nprint(\"PAD Token:\", tokenizer.pad_token)\nprint(\"PAD Token ID:\", tokenizer.convert_tokens_to_ids(tokenizer.pad_token))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:23:32.307438Z","iopub.execute_input":"2025-06-03T18:23:32.307819Z","iopub.status.idle":"2025-06-03T18:26:52.770620Z","shell.execute_reply.started":"2025-06-03T18:23:32.307785Z","shell.execute_reply":"2025-06-03T18:26:52.769856Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"220e64cfb14e47fba4be3e98d04577ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ed9ffb1bf774db18dba6b567ebb8c05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5695cdf7a2e344b99285d038093565f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bcfb4044429461faa20785eb446c45f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f667c046ffe47d496569e2e2e5ea587"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ab3a9fd42054e03ae53498ebc88ebda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f333725a34f4603847fbf5d1de7a8d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7db7bbf823f44e40a7724a1f4aba0459"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/56.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8034f5ba26c14346b4e8d1fdf5cb19e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a3fab15c4f341b2b98039ce902f4b15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa299511a09549e7861eb4c6bb2cbd4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d1480c3fa3741eda1f4d6ec87381340"}},"metadata":{}},{"name":"stderr","text":"`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9fcac8cef3f492d9bb47aee4a9566ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19745dd826a34b73847a7f29268ad4ac"}},"metadata":{}},{"name":"stdout","text":"PAD Token: <|endoftext|>\nPAD Token ID: 151643\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"print(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:26:52.771546Z","iopub.execute_input":"2025-06-03T18:26:52.772230Z","iopub.status.idle":"2025-06-03T18:26:52.778764Z","shell.execute_reply.started":"2025-06-03T18:26:52.772203Z","shell.execute_reply":"2025-06-03T18:26:52.778118Z"}},"outputs":[{"name":"stdout","text":"Qwen2VLForConditionalGeneration(\n  (visual): Qwen2VisionTransformerPretrainedModel(\n    (patch_embed): PatchEmbed(\n      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n    )\n    (rotary_pos_emb): VisionRotaryEmbedding()\n    (blocks): ModuleList(\n      (0-31): 32 x Qwen2VLVisionBlock(\n        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        (attn): VisionSdpaAttention(\n          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n        )\n        (mlp): VisionMlp(\n          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n          (act): QuickGELUActivation()\n          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n        )\n      )\n    )\n    (merger): PatchMerger(\n      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (mlp): Sequential(\n        (0): Linear(in_features=5120, out_features=5120, bias=True)\n        (1): GELU(approximate='none')\n        (2): Linear(in_features=5120, out_features=1536, bias=True)\n      )\n    )\n  )\n  (model): Qwen2VLModel(\n    (embed_tokens): Embedding(151936, 1536)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2VLDecoderLayer(\n        (self_attn): Qwen2VLSdpaAttention(\n          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n          (rotary_emb): Qwen2VLRotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n    (rotary_emb): Qwen2VLRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n)\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\nfrom peft.utils import prepare_model_for_kbit_training\n\n# ✅ Define target LoRA modules based on Qwen architecture\ntarget_modules = [\n    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n    \"fc_in\", \"fc_out\",  # These are typical for Qwen linear blocks\n]\n\n# ✅ LoRA Configuration\nlora_config = LoraConfig(\n    r=8,  # Rank\n    lora_alpha=16,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",  # or TaskType.CAUSAL_LM\n    target_modules=target_modules\n)\n\n# ✅ Prepare model for LoRA\n# Optional: if you're using 8-bit/4-bit quantization, uncomment this\n# model = prepare_model_for_kbit_training(model)\n\n# ✅ Apply LoRA\nmodel = get_peft_model(model, lora_config)\n\n# ✅ Set model to training mode\nmodel.train()\n\n# ✅ Print trainable parameters (sanity check)\n\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:26:52.779670Z","iopub.execute_input":"2025-06-03T18:26:52.780027Z","iopub.status.idle":"2025-06-03T18:26:53.349818Z","shell.execute_reply.started":"2025-06-03T18:26:52.779998Z","shell.execute_reply":"2025-06-03T18:26:53.348866Z"}},"outputs":[{"name":"stdout","text":"trainable params: 2,179,072 || all params: 2,211,164,672 || trainable%: 0.0985\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"print(dir(processor))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:26:53.350788Z","iopub.execute_input":"2025-06-03T18:26:53.351106Z","iopub.status.idle":"2025-06-03T18:26:53.355481Z","shell.execute_reply.started":"2025-06-03T18:26:53.351075Z","shell.execute_reply":"2025-06-03T18:26:53.354626Z"}},"outputs":[{"name":"stdout","text":"['__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_auto_class', '_create_repo', '_get_arguments_from_pretrained', '_get_files_timestamps', '_merge_kwargs', '_upload_modified_files', 'apply_chat_template', 'attributes', 'batch_decode', 'chat_template', 'decode', 'feature_extractor_class', 'from_args_and_dict', 'from_pretrained', 'get_processor_dict', 'image_processor', 'image_processor_class', 'image_token', 'model_input_names', 'optional_attributes', 'optional_call_args', 'post_process_image_text_to_text', 'prepare_and_validate_optional_call_args', 'push_to_hub', 'register_for_auto_class', 'save_pretrained', 'to_dict', 'to_json_file', 'to_json_string', 'tokenizer', 'tokenizer_class', 'valid_kwargs', 'validate_init_kwargs', 'video_token']\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# data prep for training","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"json\", data_files=\"/kaggle/working/dataset_qwen.jsonl\")[\"train\"]\nprint(dataset[0][\"messages\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:26:53.356209Z","iopub.execute_input":"2025-06-03T18:26:53.356445Z","iopub.status.idle":"2025-06-03T18:26:54.787830Z","shell.execute_reply.started":"2025-06-03T18:26:53.356416Z","shell.execute_reply":"2025-06-03T18:26:54.786928Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0df22b2bc84a4417ae8be16a5e1fd19a"}},"metadata":{}},{"name":"stdout","text":"[{'content': \"<image><image> Analyze the provided image and its corresponding Grad-CAM output generated by a model trained to detect fake visuals. Identify and explain artifacts that indicate it is fake. Focus primarily on the original image to identify and explain distinguishing artifacts that indicate it is fake. Use the Grad-CAM output for reference only when necessary. Provide clear, concise explanations (maximum 50 words each) using the specified artifacts below. Include positional references like 'top left' or 'bottom right' when relevant. DO NOT include any other sentences or artifacts in your response. Select only 6-7 relevant artifacts.\\nOutput Format:\\nWrite each artifact and explanation on a separate line, using the format:\\nArtifact Name: Explanation.\\nFor example:\\nUnrealistic eye reflections: Unnatural symmetrical light reflections in both eyes, suggesting generated elements.\\nOver-smoothing of natural textures: Fur appears unusually smooth in the top right, lacking natural texture variation.\\n\\nNotes:\\nExplanations should remain under 50 words for clarity.\\nAVOID referencing artifacts not listed or including extra commentary.\\n\", 'role': 'user'}, {'content': \"Blurry and inconsistent focus: The image lacks consistent sharpness, with some areas sharply defined while others are excessively blurry.\\n\\nUnnatural fur texture: The fur lacks natural variation in texture and color, appearing overly smooth and artificial.\\n\\nInconsistent lighting: The lighting is uneven and unnatural, with highlights and shadows appearing inconsistent and unrealistic.\\n\\nDistorted anatomy: The animal's features are distorted and unrealistic, particularly the facial features, which lack proper proportions.\\n\\nArtificial color saturation: Colors are overly saturated, lacking natural subtlety and gradation, particularly in the fur.\\n\\nJagged edges and pixelation: Some areas exhibit jagged edges and pixelation, especially around the edges of the animal's body.\\n\\nUnrealistic shading: Shadows and highlights on the fur are improperly rendered, lacking a natural three-dimensional appearance.\", 'role': 'assistant'}]\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"type(processor)\nmodel.device ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:26:54.788894Z","iopub.execute_input":"2025-06-03T18:26:54.789601Z","iopub.status.idle":"2025-06-03T18:26:54.794565Z","shell.execute_reply.started":"2025-06-03T18:26:54.789574Z","shell.execute_reply":"2025-06-03T18:26:54.793755Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"!pip install qwen_vl_utils\ntext = processor.apply_chat_template(\n    dataset[0][\"messages\"], tokenize=False, add_generation_prompt=True\n)\nfrom qwen_vl_utils import process_vision_info\nimage_inputs, video_inputs = process_vision_info(dataset[0][\"messages\"])\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\nprint(inputs)\ninputs = inputs.to(\"cuda\")\n\nprint(\"Generating text from the model...\")\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\nprint(f\"Generated IDs: {generated_ids}\")\n\n# Trimming the generated IDs to exclude the input tokens\nprint(\"Trimming the generated IDs to exclude the input tokens...\")\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\nprint(f\"Trimmed generated IDs: {generated_ids_trimmed}\")\n\n# Decode the generated IDs into text\nprint(\"Decoding the generated IDs to text...\")\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(f\"Decoded output text: {output_text}\")\n\n# Print final output\nprint(\"Final output text:\")\nfor text in output_text:\n    print(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:26:54.795627Z","iopub.execute_input":"2025-06-03T18:26:54.795963Z","iopub.status.idle":"2025-06-03T18:27:06.288885Z","shell.execute_reply.started":"2025-06-03T18:26:54.795929Z","shell.execute_reply":"2025-06-03T18:27:06.288073Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: qwen_vl_utils in /usr/local/lib/python3.10/dist-packages (0.0.11)\nRequirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (from qwen_vl_utils) (14.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from qwen_vl_utils) (24.2)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from qwen_vl_utils) (11.0.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from qwen_vl_utils) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->qwen_vl_utils) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->qwen_vl_utils) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->qwen_vl_utils) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->qwen_vl_utils) (2025.1.31)\n{'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198,     27,   1805,   1784,   1805,\n             29,  37427,   2986,    279,   3897,   2168,    323,   1181,  12159,\n          21794,   7658,   1402,   2550,   7907,    553,    264,   1614,  16176,\n            311,  11140,  12418,  52977,     13,  64547,    323,  10339,  35036,\n            429,  13216,    432,    374,  12418,     13,  25806,  15503,    389,\n            279,   4024,   2168,    311,  10542,    323,  10339,  84955,  35036,\n            429,  13216,    432,    374,  12418,     13,   5443,    279,  21794,\n           7658,   1402,   2550,    369,   5785,   1172,    979,   5871,     13,\n          39565,   2797,     11,  63594,  40841,    320,  39187,    220,     20,\n             15,   4244,   1817,      8,   1667,    279,   5189,  35036,   3685,\n             13,  29734,  67547,  15057,   1075,    364,   3481,   2115,      6,\n            476,    364,  14860,   1290,      6,    979,   9760,     13,   9319,\n           4183,   2924,    894,   1008,  22870,    476,  35036,    304,    697,\n           2033,     13,   8427,   1172,    220,     21,     12,     22,   9760,\n          35036,    624,   5097,  15042,    510,   7985,   1817,  36639,    323,\n          16148,    389,    264,   8651,   1555,     11,   1667,    279,   3561,\n            510,  85578,   3988,     25,  71287,    624,   2461,   3110,    510,\n           1806,   7951,   4532,   7912,  62751,     25,   1230,  52880,   7886,\n          58302,   3100,  62751,    304,   2176,   6414,     11,  22561,   7907,\n           5424,    624,   1918,   4668,  38413,    315,   5810,  29853,     25,\n          49840,   7952,  56799,  10876,    304,    279,   1909,   1290,     11,\n          31061,   5810,  10434,  22990,    382,  21667,    510,    840,  10393,\n            804,   1265,   7146,   1212,    220,     20,     15,   4244,    369,\n          31273,    624,   8093,  29805,  56516,  35036,    537,  10007,    476,\n           2670,   4960,  30610,    624, 151645,    198, 151644,  77091,    198,\n          31498,    884,    323,  39140,   5244,     25,    576,   2168,  36756,\n          12966,  17232,   2090,     11,    448,   1045,   5671,  45373,   4512,\n           1393,   3800,    525,  86046,  99055,    382,   1806,  52880,  18241,\n          10434,     25,    576,  18241,  36756,   5810,  22990,    304,  10434,\n            323,   1894,     11,  25377,  38432,  10876,    323,  20443,    382,\n            641,  78399,  17716,     25,    576,  17716,    374,  60337,    323,\n          80746,     11,    448,  21314,    323,  34512,  25377,  39140,    323,\n          70885,    382,  23356,  13595,  61590,     25,    576,   9864,    594,\n           4419,    525,  61136,    323,  70885,     11,   7945,    279,  27800,\n           4419,     11,    892,   6853,   6169,  48792,    382,   9286,  16488,\n           1894,  49743,     25,   9526,    525,  38432,  49485,     11,  31061,\n           5810,  41029,   1149,     88,    323,   5989,    367,     11,   7945,\n            304,    279,  18241,    382,     41,  96476,  12822,    323,  12955,\n            367,     25,   4329,   5671,  30224,  26742,   3556,  12822,    323,\n          12955,    367,     11,   5310,   2163,    279,  12822,    315,    279,\n           9864,    594,   2487,    382,   1806,   7951,   4532,  71734,     25,\n          66449,    323,  21314,    389,    279,  18241,    525,  74198,  22383,\n             11,  31061,    264,   5810,   2326,  32420,  11094,     13, 151645,\n            198, 151644,  77091,    198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\nGenerating text from the model...\nGenerated IDs: tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198,     27,   1805,   1784,   1805,\n             29,  37427,   2986,    279,   3897,   2168,    323,   1181,  12159,\n          21794,   7658,   1402,   2550,   7907,    553,    264,   1614,  16176,\n            311,  11140,  12418,  52977,     13,  64547,    323,  10339,  35036,\n            429,  13216,    432,    374,  12418,     13,  25806,  15503,    389,\n            279,   4024,   2168,    311,  10542,    323,  10339,  84955,  35036,\n            429,  13216,    432,    374,  12418,     13,   5443,    279,  21794,\n           7658,   1402,   2550,    369,   5785,   1172,    979,   5871,     13,\n          39565,   2797,     11,  63594,  40841,    320,  39187,    220,     20,\n             15,   4244,   1817,      8,   1667,    279,   5189,  35036,   3685,\n             13,  29734,  67547,  15057,   1075,    364,   3481,   2115,      6,\n            476,    364,  14860,   1290,      6,    979,   9760,     13,   9319,\n           4183,   2924,    894,   1008,  22870,    476,  35036,    304,    697,\n           2033,     13,   8427,   1172,    220,     21,     12,     22,   9760,\n          35036,    624,   5097,  15042,    510,   7985,   1817,  36639,    323,\n          16148,    389,    264,   8651,   1555,     11,   1667,    279,   3561,\n            510,  85578,   3988,     25,  71287,    624,   2461,   3110,    510,\n           1806,   7951,   4532,   7912,  62751,     25,   1230,  52880,   7886,\n          58302,   3100,  62751,    304,   2176,   6414,     11,  22561,   7907,\n           5424,    624,   1918,   4668,  38413,    315,   5810,  29853,     25,\n          49840,   7952,  56799,  10876,    304,    279,   1909,   1290,     11,\n          31061,   5810,  10434,  22990,    382,  21667,    510,    840,  10393,\n            804,   1265,   7146,   1212,    220,     20,     15,   4244,    369,\n          31273,    624,   8093,  29805,  56516,  35036,    537,  10007,    476,\n           2670,   4960,  30610,    624, 151645,    198, 151644,  77091,    198,\n          31498,    884,    323,  39140,   5244,     25,    576,   2168,  36756,\n          12966,  17232,   2090,     11,    448,   1045,   5671,  45373,   4512,\n           1393,   3800,    525,  86046,  99055,    382,   1806,  52880,  18241,\n          10434,     25,    576,  18241,  36756,   5810,  22990,    304,  10434,\n            323,   1894,     11,  25377,  38432,  10876,    323,  20443,    382,\n            641,  78399,  17716,     25,    576,  17716,    374,  60337,    323,\n          80746,     11,    448,  21314,    323,  34512,  25377,  39140,    323,\n          70885,    382,  23356,  13595,  61590,     25,    576,   9864,    594,\n           4419,    525,  61136,    323,  70885,     11,   7945,    279,  27800,\n           4419,     11,    892,   6853,   6169,  48792,    382,   9286,  16488,\n           1894,  49743,     25,   9526,    525,  38432,  49485,     11,  31061,\n           5810,  41029,   1149,     88,    323,   5989,    367,     11,   7945,\n            304,    279,  18241,    382,     41,  96476,  12822,    323,  12955,\n            367,     25,   4329,   5671,  30224,  26742,   3556,  12822,    323,\n          12955,    367,     11,   5310,   2163,    279,  12822,    315,    279,\n           9864,    594,   2487,    382,   1806,   7951,   4532,  71734,     25,\n          66449,    323,  21314,    389,    279,  18241,    525,  74198,  22383,\n             11,  31061,    264,   5810,   2326,  32420,  11094,     13, 151645,\n            198, 151644,  77091,    198,  85578,   3988,     25,   1230,  52880,\n          18241,  10434,    624,  69769,     25,    576,  18241,  36756,   5810,\n          22990,    304,  10434,    323,   1894,     11,  25377,  38432,  10876,\n            323,  20443,    382,  85578,   3988,     25,  27604,  13595,  61590,\n            624,  69769,     25,    576,   9864,    594,   4419,    525,  61136,\n            323,  70885,     11,   7945,    279,  27800,   4419,     11,    892,\n           6853,   6169,  48792,    382,  85578,   3988,     25,    758,  78399,\n          17716,    624,  69769,     25,    576,  17716,    374,  60337,    323,\n          80746,     11,    448,  21314,    323,  34512,  25377,  39140,    323,\n          70885,    382,  85578,   3988,     25,   1230,   7951,   4532,   7912,\n          62751,    624,  69769,     25,   1230,  52880,   7886,  58302,   3100,\n          62751,    304,   2176,   6414,     11,  22561,   7907,   5424,    382,\n          85578,   3988,     25,   1230,   7951,   4532,  71734,    624,  69769,\n             25,  66449,    323,  21314,    389,    279,  18241,    525,  74198,\n          22383,     11,  31061,    264,   5810,   2326]], device='cuda:0')\nTrimming the generated IDs to exclude the input tokens...\nTrimmed generated IDs: [tensor([85578,  3988,    25,  1230, 52880, 18241, 10434,   624, 69769,    25,\n          576, 18241, 36756,  5810, 22990,   304, 10434,   323,  1894,    11,\n        25377, 38432, 10876,   323, 20443,   382, 85578,  3988,    25, 27604,\n        13595, 61590,   624, 69769,    25,   576,  9864,   594,  4419,   525,\n        61136,   323, 70885,    11,  7945,   279, 27800,  4419,    11,   892,\n         6853,  6169, 48792,   382, 85578,  3988,    25,   758, 78399, 17716,\n          624, 69769,    25,   576, 17716,   374, 60337,   323, 80746,    11,\n          448, 21314,   323, 34512, 25377, 39140,   323, 70885,   382, 85578,\n         3988,    25,  1230,  7951,  4532,  7912, 62751,   624, 69769,    25,\n         1230, 52880,  7886, 58302,  3100, 62751,   304,  2176,  6414,    11,\n        22561,  7907,  5424,   382, 85578,  3988,    25,  1230,  7951,  4532,\n        71734,   624, 69769,    25, 66449,   323, 21314,   389,   279, 18241,\n          525, 74198, 22383,    11, 31061,   264,  5810,  2326],\n       device='cuda:0')]\nDecoding the generated IDs to text...\nDecoded output text: [\"Artifact Name: Unnatural fur texture.\\nExplanation: The fur lacks natural variation in texture and color, appearing overly smooth and artificial.\\n\\nArtifact Name: Distorted anatomy.\\nExplanation: The animal's features are distorted and unrealistic, particularly the facial features, which lack proper proportions.\\n\\nArtifact Name: Inconsistent lighting.\\nExplanation: The lighting is uneven and unnatural, with highlights and shadows appearing inconsistent and unrealistic.\\n\\nArtifact Name: Unrealistic eye reflections.\\nExplanation: Unnatural symmetrical light reflections in both eyes, suggesting generated elements.\\n\\nArtifact Name: Unrealistic shading.\\nExplanation: Shadows and highlights on the fur are improperly rendered, lacking a natural three\"]\nFinal output text:\nArtifact Name: Unnatural fur texture.\nExplanation: The fur lacks natural variation in texture and color, appearing overly smooth and artificial.\n\nArtifact Name: Distorted anatomy.\nExplanation: The animal's features are distorted and unrealistic, particularly the facial features, which lack proper proportions.\n\nArtifact Name: Inconsistent lighting.\nExplanation: The lighting is uneven and unnatural, with highlights and shadows appearing inconsistent and unrealistic.\n\nArtifact Name: Unrealistic eye reflections.\nExplanation: Unnatural symmetrical light reflections in both eyes, suggesting generated elements.\n\nArtifact Name: Unrealistic shading.\nExplanation: Shadows and highlights on the fur are improperly rendered, lacking a natural three\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:27:06.289805Z","iopub.execute_input":"2025-06-03T18:27:06.290112Z","iopub.status.idle":"2025-06-03T18:27:06.306504Z","shell.execute_reply.started":"2025-06-03T18:27:06.290077Z","shell.execute_reply":"2025-06-03T18:27:06.305674Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198,     27,   1805,   1784,   1805,\n             29,  37427,   2986,    279,   3897,   2168,    323,   1181,  12159,\n          21794,   7658,   1402,   2550,   7907,    553,    264,   1614,  16176,\n            311,  11140,  12418,  52977,     13,  64547,    323,  10339,  35036,\n            429,  13216,    432,    374,  12418,     13,  25806,  15503,    389,\n            279,   4024,   2168,    311,  10542,    323,  10339,  84955,  35036,\n            429,  13216,    432,    374,  12418,     13,   5443,    279,  21794,\n           7658,   1402,   2550,    369,   5785,   1172,    979,   5871,     13,\n          39565,   2797,     11,  63594,  40841,    320,  39187,    220,     20,\n             15,   4244,   1817,      8,   1667,    279,   5189,  35036,   3685,\n             13,  29734,  67547,  15057,   1075,    364,   3481,   2115,      6,\n            476,    364,  14860,   1290,      6,    979,   9760,     13,   9319,\n           4183,   2924,    894,   1008,  22870,    476,  35036,    304,    697,\n           2033,     13,   8427,   1172,    220,     21,     12,     22,   9760,\n          35036,    624,   5097,  15042,    510,   7985,   1817,  36639,    323,\n          16148,    389,    264,   8651,   1555,     11,   1667,    279,   3561,\n            510,  85578,   3988,     25,  71287,    624,   2461,   3110,    510,\n           1806,   7951,   4532,   7912,  62751,     25,   1230,  52880,   7886,\n          58302,   3100,  62751,    304,   2176,   6414,     11,  22561,   7907,\n           5424,    624,   1918,   4668,  38413,    315,   5810,  29853,     25,\n          49840,   7952,  56799,  10876,    304,    279,   1909,   1290,     11,\n          31061,   5810,  10434,  22990,    382,  21667,    510,    840,  10393,\n            804,   1265,   7146,   1212,    220,     20,     15,   4244,    369,\n          31273,    624,   8093,  29805,  56516,  35036,    537,  10007,    476,\n           2670,   4960,  30610,    624, 151645,    198, 151644,  77091,    198,\n          31498,    884,    323,  39140,   5244,     25,    576,   2168,  36756,\n          12966,  17232,   2090,     11,    448,   1045,   5671,  45373,   4512,\n           1393,   3800,    525,  86046,  99055,    382,   1806,  52880,  18241,\n          10434,     25,    576,  18241,  36756,   5810,  22990,    304,  10434,\n            323,   1894,     11,  25377,  38432,  10876,    323,  20443,    382,\n            641,  78399,  17716,     25,    576,  17716,    374,  60337,    323,\n          80746,     11,    448,  21314,    323,  34512,  25377,  39140,    323,\n          70885,    382,  23356,  13595,  61590,     25,    576,   9864,    594,\n           4419,    525,  61136,    323,  70885,     11,   7945,    279,  27800,\n           4419,     11,    892,   6853,   6169,  48792,    382,   9286,  16488,\n           1894,  49743,     25,   9526,    525,  38432,  49485,     11,  31061,\n           5810,  41029,   1149,     88,    323,   5989,    367,     11,   7945,\n            304,    279,  18241,    382,     41,  96476,  12822,    323,  12955,\n            367,     25,   4329,   5671,  30224,  26742,   3556,  12822,    323,\n          12955,    367,     11,   5310,   2163,    279,  12822,    315,    279,\n           9864,    594,   2487,    382,   1806,   7951,   4532,  71734,     25,\n          66449,    323,  21314,    389,    279,  18241,    525,  74198,  22383,\n             11,  31061,    264,   5810,   2326,  32420,  11094,     13, 151645,\n            198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport torch\nfrom qwen_vl_utils import process_vision_info\n\nclass QwenVLDataset(Dataset):\n    def __init__(self, dataset, processor):\n        self.dataset = dataset\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        data = self.dataset[idx]\n        messages = data[\"messages\"]\n\n        # 1. Prepare chat text with generation prompt\n        text = self.processor.apply_chat_template(\n            messages, tokenize=False, add_generation_prompt=True\n        )\n\n        # 2. Process vision inputs\n        image_inputs, video_inputs = process_vision_info(messages)\n\n        # 3. Tokenize + prepare model inputs\n        inputs = self.processor(\n            text=[text],\n            images=image_inputs,\n            videos=video_inputs,\n            padding=\"longest\",\n            return_tensors=\"pt\"\n        )\n\n        # 4. Get input_ids and labels\n        input_ids = inputs[\"input_ids\"][0]\n        attention_mask = inputs[\"attention_mask\"][0]\n\n        # 5. Identify where the generation starts — label only the expected output\n        # Assume the assistant's last message is the target\n        target_text = messages[-1][\"content\"]\n        target_token_ids = self.processor.tokenizer(\n            target_text, return_tensors=\"pt\", add_special_tokens=False\n        )[\"input_ids\"][0]\n\n        labels = torch.full_like(input_ids, fill_value=-100)  # mask everything\n        labels[-len(target_token_ids):] = target_token_ids  # only train on target\n\n        return {\n            \n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"labels\": labels\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:27:06.307142Z","iopub.execute_input":"2025-06-03T18:27:06.307336Z","iopub.status.idle":"2025-06-03T18:27:07.935618Z","shell.execute_reply.started":"2025-06-03T18:27:06.307319Z","shell.execute_reply":"2025-06-03T18:27:07.934646Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"train_dataset = QwenVLDataset(dataset, processor)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:27:07.936602Z","iopub.execute_input":"2025-06-03T18:27:07.936937Z","iopub.status.idle":"2025-06-03T18:27:07.953681Z","shell.execute_reply.started":"2025-06-03T18:27:07.936906Z","shell.execute_reply":"2025-06-03T18:27:07.952955Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'].shape)\nprint(train_dataset[3]['input_ids'].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:27:07.954559Z","iopub.execute_input":"2025-06-03T18:27:07.954892Z","iopub.status.idle":"2025-06-03T18:27:07.973090Z","shell.execute_reply.started":"2025-06-03T18:27:07.954861Z","shell.execute_reply":"2025-06-03T18:27:07.972267Z"}},"outputs":[{"name":"stdout","text":"torch.Size([400])\ntorch.Size([375])\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"len(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:27:07.974034Z","iopub.execute_input":"2025-06-03T18:27:07.974443Z","iopub.status.idle":"2025-06-03T18:27:07.979243Z","shell.execute_reply.started":"2025-06-03T18:27:07.974413Z","shell.execute_reply":"2025-06-03T18:27:07.978526Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nfrom transformers import default_data_collator\n\ndata_collator = default_data_collator\ntraining_args = TrainingArguments(\n    output_dir=\"./qwen-lora\",\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4,\n    save_strategy=\"steps\",\n    save_steps=100,\n    num_train_epochs=5,\n    learning_rate=2e-4,\n    fp16=True,\n    report_to=\"none\"\n)\n\n# Dataset should return: {\"messages\": [...], \"images\": [...]}\ntrainer = Trainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=training_args,\n    train_dataset=train_dataset,\n    data_collator=data_collator\n)\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:27:07.979844Z","iopub.execute_input":"2025-06-03T18:27:07.980030Z","iopub.status.idle":"2025-06-03T18:28:03.994904Z","shell.execute_reply.started":"2025-06-03T18:27:07.980013Z","shell.execute_reply":"2025-06-03T18:28:03.994029Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:51, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=25, training_loss=10.206959838867187, metrics={'train_runtime': 54.2389, 'train_samples_per_second': 1.844, 'train_steps_per_second': 0.461, 'total_flos': 472474486256640.0, 'train_loss': 10.206959838867187, 'epoch': 5.0})"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"text = processor.apply_chat_template(\n    dataset[1][\"messages\"], tokenize=False, add_generation_prompt=True\n)\nfrom qwen_vl_utils import process_vision_info\nimage_inputs, video_inputs = process_vision_info(dataset[1][\"messages\"])\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\ninputs = inputs.to(\"cuda\")\n\nprint(\"Generating text from the model...\")\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\nprint(f\"Generated IDs: {generated_ids}\")\n\n# Trimming the generated IDs to exclude the input tokens\nprint(\"Trimming the generated IDs to exclude the input tokens...\")\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\nprint(f\"Trimmed generated IDs: {generated_ids_trimmed}\")\n\n# Decode the generated IDs into text\nprint(\"Decoding the generated IDs to text...\")\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(f\"Decoded output text: {output_text}\")\n\n# Print final output\nprint(\"Final output text:\")\nfor text in output_text:\n    print(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:28:03.995705Z","iopub.execute_input":"2025-06-03T18:28:03.995940Z","iopub.status.idle":"2025-06-03T18:28:11.692595Z","shell.execute_reply.started":"2025-06-03T18:28:03.995919Z","shell.execute_reply":"2025-06-03T18:28:11.691686Z"}},"outputs":[{"name":"stdout","text":"Generating text from the model...\nGenerated IDs: tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198,     27,   1805,   1784,   1805,\n             29,  37427,   2986,    279,   3897,   2168,    323,   1181,  12159,\n          21794,   7658,   1402,   2550,   7907,    553,    264,   1614,  16176,\n            311,  11140,  12418,  52977,     13,  64547,    323,  10339,  35036,\n            429,  13216,    432,    374,  12418,     13,  25806,  15503,    389,\n            279,   4024,   2168,    311,  10542,    323,  10339,  84955,  35036,\n            429,  13216,    432,    374,  12418,     13,   5443,    279,  21794,\n           7658,   1402,   2550,    369,   5785,   1172,    979,   5871,     13,\n          39565,   2797,     11,  63594,  40841,    320,  39187,    220,     20,\n             15,   4244,   1817,      8,   1667,    279,   5189,  35036,   3685,\n             13,  29734,  67547,  15057,   1075,    364,   3481,   2115,      6,\n            476,    364,  14860,   1290,      6,    979,   9760,     13,   9319,\n           4183,   2924,    894,   1008,  22870,    476,  35036,    304,    697,\n           2033,     13,   8427,   1172,    220,     21,     12,     22,   9760,\n          35036,    624,   5097,  15042,    510,   7985,   1817,  36639,    323,\n          16148,    389,    264,   8651,   1555,     11,   1667,    279,   3561,\n            510,  85578,   3988,     25,  71287,    624,   2461,   3110,    510,\n           1806,   7951,   4532,   7912,  62751,     25,   1230,  52880,   7886,\n          58302,   3100,  62751,    304,   2176,   6414,     11,  22561,   7907,\n           5424,    624,   1918,   4668,  38413,    315,   5810,  29853,     25,\n          49840,   7952,  56799,  10876,    304,    279,   1909,   1290,     11,\n          31061,   5810,  10434,  22990,    382,  21667,    510,    840,  10393,\n            804,   1265,   7146,   1212,    220,     20,     15,   4244,    369,\n          31273,    624,   8093,  29805,  56516,  35036,    537,  10007,    476,\n           2670,   4960,  30610,    624, 151645,    198, 151644,  77091,    198,\n          31498,    884,  12822,     25,    220,    576,  12822,    315,    279,\n           7071,     11,   7945,   2163,    279,   1968,    323,  26906,     11,\n           6853,  17232,   2090,    323,   7271,     11,  18860,    264,   4650,\n           9471,  36639,    382,   1806,  52880,  18241,  10434,     25,    576,\n          18241,  10434,   7952,  79861,   4402,  10876,    323,  36756,    279,\n           5810,  22990,   3601,    304,   1931,   9864,  18241,    382,   1636,\n          91822,     25,  24742,    480,  91822,    304,   1894,  49743,    323,\n          16232,   3941,    279,   7071,    594,   2487,    323,   4004,    382,\n             43,    473,    315,   6915,   7716,     25,    576,   2168,  36756,\n           6915,   3565,    304,    279,  27800,   4419,    323,  18241,     11,\n          25377,  38432,  66117,    382,   9286,  16488,  17716,     25,    220,\n            576,  17716,   7952,  80746,    323,  39140,     11,  22561,    279,\n            990,    315,  20443,  17716,   8173,   2878,    264,   7907,   4573,\n            382,  23356,  13595,  48792,     25,    220,    576,   9864,    594,\n          48792,   4994,  10078,   1007,     11,    448,    264,   1968,    429,\n           1231,    387,  72052,   3460,   7707,    311,   1181,   2487,    382,\n             41,  96476,  12822,     25,   3719,  11239,  26742,   3556,  12822,\n           9434,   2163,    279,  18732,   1948,    279,   9864,    323,    279,\n           4004,     13, 151645,    198, 151644,  77091,    198,   1806,   7951,\n           4532,   7912,  62751,     25,  79919,   4532,   7886,  58302,   3100,\n          62751,    304,   2176,   6414,     11,  22561,   7907,   5424,    382,\n           1918,   4668,  38413,    315,   5810,  29853,     25,  49840,   7952,\n          56799,  10876,    304,    279,   1909,   1290,     11,  31061,   5810,\n          10434,  22990,    382,  31498,    884,  12822,     25,    220,    576,\n          12822,    315,    279,   7071,     11,   7945,   2163,    279,   1968,\n            323,  26906,     11,   6853,  17232,   2090,    323,   7271,     11,\n          18860,    264,   4650,   9471,  36639,    382,   1806,  52880,  18241,\n          10434,     25,    576,  18241,  10434,   7952,  79861,   4402,  10876,\n            323,  36756,    279,   5810,  22990,   3601,    304,   1931,   9864,\n          18241,    382,   1636,  91822,     25,  24742,    480,  91822,    304,\n           1894,  49743,    323,  16232,   3941,    279,   7071,    594,   2487,\n            323,   4004,    382,     43,    473,    315,   6915,   7716,     25,\n            576,   2168,  36756,   6915,   3565,    304,    279,  27800,   4419]],\n       device='cuda:0')\nTrimming the generated IDs to exclude the input tokens...\nTrimmed generated IDs: [tensor([ 1806,  7951,  4532,  7912, 62751,    25, 79919,  4532,  7886, 58302,\n         3100, 62751,   304,  2176,  6414,    11, 22561,  7907,  5424,   382,\n         1918,  4668, 38413,   315,  5810, 29853,    25, 49840,  7952, 56799,\n        10876,   304,   279,  1909,  1290,    11, 31061,  5810, 10434, 22990,\n          382, 31498,   884, 12822,    25,   220,   576, 12822,   315,   279,\n         7071,    11,  7945,  2163,   279,  1968,   323, 26906,    11,  6853,\n        17232,  2090,   323,  7271,    11, 18860,   264,  4650,  9471, 36639,\n          382,  1806, 52880, 18241, 10434,    25,   576, 18241, 10434,  7952,\n        79861,  4402, 10876,   323, 36756,   279,  5810, 22990,  3601,   304,\n         1931,  9864, 18241,   382,  1636, 91822,    25, 24742,   480, 91822,\n          304,  1894, 49743,   323, 16232,  3941,   279,  7071,   594,  2487,\n          323,  4004,   382,    43,   473,   315,  6915,  7716,    25,   576,\n         2168, 36756,  6915,  3565,   304,   279, 27800,  4419],\n       device='cuda:0')]\nDecoding the generated IDs to text...\nDecoded output text: [\"Unrealistic eye reflections: Unrealistic symmetrical light reflections in both eyes, suggesting generated elements.\\n\\nOver-smoothing of natural textures: Fur appears unusually smooth in the top right, lacking natural texture variation.\\n\\nBlurry edges:  The edges of the figure, particularly around the head and shoulders, lack sharpness and definition, indicating a potential generation artifact.\\n\\nUnnatural fur texture: The fur texture appears inconsistently smooth and lacks the natural variation expected in real animal fur.\\n\\nColor inconsistencies: Noticeable inconsistencies in color saturation and tone across the figure's body and background.\\n\\nLack of fine detail: The image lacks fine details in the facial features\"]\nFinal output text:\nUnrealistic eye reflections: Unrealistic symmetrical light reflections in both eyes, suggesting generated elements.\n\nOver-smoothing of natural textures: Fur appears unusually smooth in the top right, lacking natural texture variation.\n\nBlurry edges:  The edges of the figure, particularly around the head and shoulders, lack sharpness and definition, indicating a potential generation artifact.\n\nUnnatural fur texture: The fur texture appears inconsistently smooth and lacks the natural variation expected in real animal fur.\n\nColor inconsistencies: Noticeable inconsistencies in color saturation and tone across the figure's body and background.\n\nLack of fine detail: The image lacks fine details in the facial features\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/qwen-finetuned\")\ntokenizer.save_pretrained(\"/kaggle/working/qwen-finetuned\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:28:11.693415Z","iopub.execute_input":"2025-06-03T18:28:11.693665Z","iopub.status.idle":"2025-06-03T18:28:12.472028Z","shell.execute_reply.started":"2025-06-03T18:28:11.693647Z","shell.execute_reply":"2025-06-03T18:28:12.471254Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/qwen-finetuned/tokenizer_config.json',\n '/kaggle/working/qwen-finetuned/special_tokens_map.json',\n '/kaggle/working/qwen-finetuned/vocab.json',\n '/kaggle/working/qwen-finetuned/merges.txt',\n '/kaggle/working/qwen-finetuned/added_tokens.json',\n '/kaggle/working/qwen-finetuned/tokenizer.json')"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive('/kaggle/working/myqwenfirst', 'zip', '/kaggle/working/qwen-finetuned_model')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:28:12.472891Z","iopub.execute_input":"2025-06-03T18:28:12.473226Z","iopub.status.idle":"2025-06-03T18:28:12.478848Z","shell.execute_reply.started":"2025-06-03T18:28:12.473193Z","shell.execute_reply":"2025-06-03T18:28:12.477982Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/myqwenfirst.zip'"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer,AutoModelForVision2Seq\n\nmodel = AutoModelForVision2Seq.from_pretrained(\"/kaggle/working/qwen-finetuned\")\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/qwen-finetuned\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:28:12.479802Z","iopub.execute_input":"2025-06-03T18:28:12.480119Z","iopub.status.idle":"2025-06-03T18:28:18.555587Z","shell.execute_reply.started":"2025-06-03T18:28:12.480090Z","shell.execute_reply":"2025-06-03T18:28:18.554839Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91effc5301ae4cdc85bcfd683d0e4af4"}},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.device ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:28:18.556461Z","iopub.execute_input":"2025-06-03T18:28:18.556766Z","iopub.status.idle":"2025-06-03T18:28:21.043469Z","shell.execute_reply.started":"2025-06-03T18:28:18.556736Z","shell.execute_reply":"2025-06-03T18:28:21.042644Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:28:21.044209Z","iopub.execute_input":"2025-06-03T18:28:21.044495Z","iopub.status.idle":"2025-06-03T18:28:21.055379Z","shell.execute_reply.started":"2025-06-03T18:28:21.044474Z","shell.execute_reply":"2025-06-03T18:28:21.054557Z"}},"outputs":[{"name":"stdout","text":"Qwen2VLForConditionalGeneration(\n  (visual): Qwen2VisionTransformerPretrainedModel(\n    (patch_embed): PatchEmbed(\n      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n    )\n    (rotary_pos_emb): VisionRotaryEmbedding()\n    (blocks): ModuleList(\n      (0-31): 32 x Qwen2VLVisionBlock(\n        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n        (attn): VisionSdpaAttention(\n          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n        )\n        (mlp): VisionMlp(\n          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n          (act): QuickGELUActivation()\n          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n        )\n      )\n    )\n    (merger): PatchMerger(\n      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (mlp): Sequential(\n        (0): Linear(in_features=5120, out_features=5120, bias=True)\n        (1): GELU(approximate='none')\n        (2): Linear(in_features=5120, out_features=1536, bias=True)\n      )\n    )\n  )\n  (model): Qwen2VLModel(\n    (embed_tokens): Embedding(151936, 1536)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2VLDecoderLayer(\n        (self_attn): Qwen2VLSdpaAttention(\n          (q_proj): lora.Linear(\n            (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n            (lora_dropout): ModuleDict(\n              (default): Dropout(p=0.05, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=1536, out_features=8, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=8, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear(\n            (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n            (lora_dropout): ModuleDict(\n              (default): Dropout(p=0.05, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=1536, out_features=8, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=8, out_features=256, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear(\n            (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n            (lora_dropout): ModuleDict(\n              (default): Dropout(p=0.05, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=1536, out_features=8, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=8, out_features=256, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear(\n            (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n            (lora_dropout): ModuleDict(\n              (default): Dropout(p=0.05, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=1536, out_features=8, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=8, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): Qwen2VLRotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n    (rotary_emb): Qwen2VLRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n)\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"text = processor.apply_chat_template(\n    dataset[0][\"messages\"], tokenize=False, add_generation_prompt=True\n)\nfrom qwen_vl_utils import process_vision_info\nimage_inputs, video_inputs = process_vision_info(dataset[0][\"messages\"])\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\ninputs = inputs.to(\"cuda\")\n\nprint(\"Generating text from the model...\")\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\nprint(f\"Generated IDs: {generated_ids}\")\n\n# Trimming the generated IDs to exclude the input tokens\nprint(\"Trimming the generated IDs to exclude the input tokens...\")\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\nprint(f\"Trimmed generated IDs: {generated_ids_trimmed}\")\n\n# Decode the generated IDs into text\nprint(\"Decoding the generated IDs to text...\")\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\nprint(f\"Decoded output text: {output_text}\")\n\n# Print final output\nprint(\"Final output text:\")\nfor text in output_text:\n    print(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:28:21.056376Z","iopub.execute_input":"2025-06-03T18:28:21.056682Z","iopub.status.idle":"2025-06-03T18:28:27.644385Z","shell.execute_reply.started":"2025-06-03T18:28:21.056653Z","shell.execute_reply":"2025-06-03T18:28:27.643593Z"}},"outputs":[{"name":"stdout","text":"Generating text from the model...\nGenerated IDs: tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198,     27,   1805,   1784,   1805,\n             29,  37427,   2986,    279,   3897,   2168,    323,   1181,  12159,\n          21794,   7658,   1402,   2550,   7907,    553,    264,   1614,  16176,\n            311,  11140,  12418,  52977,     13,  64547,    323,  10339,  35036,\n            429,  13216,    432,    374,  12418,     13,  25806,  15503,    389,\n            279,   4024,   2168,    311,  10542,    323,  10339,  84955,  35036,\n            429,  13216,    432,    374,  12418,     13,   5443,    279,  21794,\n           7658,   1402,   2550,    369,   5785,   1172,    979,   5871,     13,\n          39565,   2797,     11,  63594,  40841,    320,  39187,    220,     20,\n             15,   4244,   1817,      8,   1667,    279,   5189,  35036,   3685,\n             13,  29734,  67547,  15057,   1075,    364,   3481,   2115,      6,\n            476,    364,  14860,   1290,      6,    979,   9760,     13,   9319,\n           4183,   2924,    894,   1008,  22870,    476,  35036,    304,    697,\n           2033,     13,   8427,   1172,    220,     21,     12,     22,   9760,\n          35036,    624,   5097,  15042,    510,   7985,   1817,  36639,    323,\n          16148,    389,    264,   8651,   1555,     11,   1667,    279,   3561,\n            510,  85578,   3988,     25,  71287,    624,   2461,   3110,    510,\n           1806,   7951,   4532,   7912,  62751,     25,   1230,  52880,   7886,\n          58302,   3100,  62751,    304,   2176,   6414,     11,  22561,   7907,\n           5424,    624,   1918,   4668,  38413,    315,   5810,  29853,     25,\n          49840,   7952,  56799,  10876,    304,    279,   1909,   1290,     11,\n          31061,   5810,  10434,  22990,    382,  21667,    510,    840,  10393,\n            804,   1265,   7146,   1212,    220,     20,     15,   4244,    369,\n          31273,    624,   8093,  29805,  56516,  35036,    537,  10007,    476,\n           2670,   4960,  30610,    624, 151645,    198, 151644,  77091,    198,\n          31498,    884,    323,  39140,   5244,     25,    576,   2168,  36756,\n          12966,  17232,   2090,     11,    448,   1045,   5671,  45373,   4512,\n           1393,   3800,    525,  86046,  99055,    382,   1806,  52880,  18241,\n          10434,     25,    576,  18241,  36756,   5810,  22990,    304,  10434,\n            323,   1894,     11,  25377,  38432,  10876,    323,  20443,    382,\n            641,  78399,  17716,     25,    576,  17716,    374,  60337,    323,\n          80746,     11,    448,  21314,    323,  34512,  25377,  39140,    323,\n          70885,    382,  23356,  13595,  61590,     25,    576,   9864,    594,\n           4419,    525,  61136,    323,  70885,     11,   7945,    279,  27800,\n           4419,     11,    892,   6853,   6169,  48792,    382,   9286,  16488,\n           1894,  49743,     25,   9526,    525,  38432,  49485,     11,  31061,\n           5810,  41029,   1149,     88,    323,   5989,    367,     11,   7945,\n            304,    279,  18241,    382,     41,  96476,  12822,    323,  12955,\n            367,     25,   4329,   5671,  30224,  26742,   3556,  12822,    323,\n          12955,    367,     11,   5310,   2163,    279,  12822,    315,    279,\n           9864,    594,   2487,    382,   1806,   7951,   4532,  71734,     25,\n          66449,    323,  21314,    389,    279,  18241,    525,  74198,  22383,\n             11,  31061,    264,   5810,   2326,  32420,  11094,     13, 151645,\n            198, 151644,  77091,    198,   1806,   7951,   4532,   7912,  62751,\n             25,   1230,  52880,   7886,  58302,   3100,  62751,    304,   2176,\n           6414,     11,  22561,   7907,   5424,    382,   1918,   4668,  38413,\n            315,   5810,  29853,     25,  49840,   7952,  56799,  10876,    304,\n            279,   1909,   1290,     11,  31061,   5810,  10434,  22990,    382,\n           1806,   7951,   4532,  18241,  10434,     25,    576,  18241,  36756,\n           5810,  22990,    304,  10434,    323,   1894,     11,  25377,  38432,\n          10876,    323,  20443,    382,    641,  78399,  17716,     25,    576,\n          17716,    374,  60337,    323,  80746,     11,    448,  21314,    323,\n          34512,  25377,  39140,    323,  70885,    382,  23356,  13595,  61590,\n             25,    576,   9864,    594,   4419,    525,  61136,    323,  70885,\n             11,   7945,    279,  27800,   4419,     11,    892,   6853,   6169,\n          48792,    382,   9286,  16488,   1894,  49743,     25,   9526,    525,\n          38432,  49485,     11,  31061,   5810,  41029,   1149,     88,    323,\n           5989,    367,     11,   7945,    304,    279]], device='cuda:0')\nTrimming the generated IDs to exclude the input tokens...\nTrimmed generated IDs: [tensor([ 1806,  7951,  4532,  7912, 62751,    25,  1230, 52880,  7886, 58302,\n         3100, 62751,   304,  2176,  6414,    11, 22561,  7907,  5424,   382,\n         1918,  4668, 38413,   315,  5810, 29853,    25, 49840,  7952, 56799,\n        10876,   304,   279,  1909,  1290,    11, 31061,  5810, 10434, 22990,\n          382,  1806,  7951,  4532, 18241, 10434,    25,   576, 18241, 36756,\n         5810, 22990,   304, 10434,   323,  1894,    11, 25377, 38432, 10876,\n          323, 20443,   382,   641, 78399, 17716,    25,   576, 17716,   374,\n        60337,   323, 80746,    11,   448, 21314,   323, 34512, 25377, 39140,\n          323, 70885,   382, 23356, 13595, 61590,    25,   576,  9864,   594,\n         4419,   525, 61136,   323, 70885,    11,  7945,   279, 27800,  4419,\n           11,   892,  6853,  6169, 48792,   382,  9286, 16488,  1894, 49743,\n           25,  9526,   525, 38432, 49485,    11, 31061,  5810, 41029,  1149,\n           88,   323,  5989,   367,    11,  7945,   304,   279],\n       device='cuda:0')]\nDecoding the generated IDs to text...\nDecoded output text: [\"Unrealistic eye reflections: Unnatural symmetrical light reflections in both eyes, suggesting generated elements.\\n\\nOver-smoothing of natural textures: Fur appears unusually smooth in the top right, lacking natural texture variation.\\n\\nUnrealistic fur texture: The fur lacks natural variation in texture and color, appearing overly smooth and artificial.\\n\\nInconsistent lighting: The lighting is uneven and unnatural, with highlights and shadows appearing inconsistent and unrealistic.\\n\\nDistorted anatomy: The animal's features are distorted and unrealistic, particularly the facial features, which lack proper proportions.\\n\\nArtificial color saturation: Colors are overly saturated, lacking natural subtlety and gradation, particularly in the\"]\nFinal output text:\nUnrealistic eye reflections: Unnatural symmetrical light reflections in both eyes, suggesting generated elements.\n\nOver-smoothing of natural textures: Fur appears unusually smooth in the top right, lacking natural texture variation.\n\nUnrealistic fur texture: The fur lacks natural variation in texture and color, appearing overly smooth and artificial.\n\nInconsistent lighting: The lighting is uneven and unnatural, with highlights and shadows appearing inconsistent and unrealistic.\n\nDistorted anatomy: The animal's features are distorted and unrealistic, particularly the facial features, which lack proper proportions.\n\nArtificial color saturation: Colors are overly saturated, lacking natural subtlety and gradation, particularly in the\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport torch\n\nfrom qwen_vl_utils import process_vision_info\n\n# Prepare the input text using chat template\ntext = processor.apply_chat_template(\n    dataset[0][\"messages\"], tokenize=False, add_generation_prompt=True\n)\n\n# Extract image and video inputs from the message\nimage_inputs, video_inputs = process_vision_info(dataset[0][\"messages\"])\n\n# Tokenize and convert to tensors\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\n\n# Move tensors to GPU\ninputs = inputs.to(\"cuda\")\n\n# Generate predictions\nprint(\"Generating text from the model...\")\ngenerated_ids = model.generate(**inputs, max_new_tokens=128)\nprint(f\"Generated IDs: {generated_ids}\")\n\n# Trim generated tokens to exclude input tokens\nprint(\"Trimming the generated IDs to exclude the input tokens...\")\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\nprint(f\"Trimmed generated IDs: {generated_ids_trimmed}\")\n\n# Decode the output tokens to text\nprint(\"Decoding the generated IDs to text...\")\noutput_text = processor.batch_decode(\n    generated_ids_trimmed,\n    skip_special_tokens=True,\n    clean_up_tokenization_spaces=False,\n)\nprint(\"Final output text:\")\n\n# Display output text and corresponding images\nfor idx, text in enumerate(output_text):\n    print(f\"\\n--- Output {idx + 1} ---\")\n    print(text)\n\n    # Display corresponding image if available\n    if image_inputs and idx < len(image_inputs):\n        image = image_inputs[idx]\n\n        # Convert tensor to PIL image if needed\n        if isinstance(image, torch.Tensor):\n            # Assume shape: (C, H, W); normalize values to 0-1\n            image = image.detach().cpu()\n            image = image.permute(1, 2, 0).clamp(0, 1).numpy()\n            plt.imshow(image)\n        elif isinstance(image, Image.Image):\n            plt.imshow(image)\n        else:\n            print(f\"Unsupported image format for index {idx}\")\n            continue\n\n        plt.axis(\"off\")\n        plt.title(f\"Image for Output {idx + 1}\")\n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:34:02.928635Z","iopub.execute_input":"2025-06-03T18:34:02.929010Z","iopub.status.idle":"2025-06-03T18:34:09.534012Z","shell.execute_reply.started":"2025-06-03T18:34:02.928984Z","shell.execute_reply":"2025-06-03T18:34:09.533192Z"}},"outputs":[{"name":"stdout","text":"Generating text from the model...\nGenerated IDs: tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198,     27,   1805,   1784,   1805,\n             29,  37427,   2986,    279,   3897,   2168,    323,   1181,  12159,\n          21794,   7658,   1402,   2550,   7907,    553,    264,   1614,  16176,\n            311,  11140,  12418,  52977,     13,  64547,    323,  10339,  35036,\n            429,  13216,    432,    374,  12418,     13,  25806,  15503,    389,\n            279,   4024,   2168,    311,  10542,    323,  10339,  84955,  35036,\n            429,  13216,    432,    374,  12418,     13,   5443,    279,  21794,\n           7658,   1402,   2550,    369,   5785,   1172,    979,   5871,     13,\n          39565,   2797,     11,  63594,  40841,    320,  39187,    220,     20,\n             15,   4244,   1817,      8,   1667,    279,   5189,  35036,   3685,\n             13,  29734,  67547,  15057,   1075,    364,   3481,   2115,      6,\n            476,    364,  14860,   1290,      6,    979,   9760,     13,   9319,\n           4183,   2924,    894,   1008,  22870,    476,  35036,    304,    697,\n           2033,     13,   8427,   1172,    220,     21,     12,     22,   9760,\n          35036,    624,   5097,  15042,    510,   7985,   1817,  36639,    323,\n          16148,    389,    264,   8651,   1555,     11,   1667,    279,   3561,\n            510,  85578,   3988,     25,  71287,    624,   2461,   3110,    510,\n           1806,   7951,   4532,   7912,  62751,     25,   1230,  52880,   7886,\n          58302,   3100,  62751,    304,   2176,   6414,     11,  22561,   7907,\n           5424,    624,   1918,   4668,  38413,    315,   5810,  29853,     25,\n          49840,   7952,  56799,  10876,    304,    279,   1909,   1290,     11,\n          31061,   5810,  10434,  22990,    382,  21667,    510,    840,  10393,\n            804,   1265,   7146,   1212,    220,     20,     15,   4244,    369,\n          31273,    624,   8093,  29805,  56516,  35036,    537,  10007,    476,\n           2670,   4960,  30610,    624, 151645,    198, 151644,  77091,    198,\n          31498,    884,    323,  39140,   5244,     25,    576,   2168,  36756,\n          12966,  17232,   2090,     11,    448,   1045,   5671,  45373,   4512,\n           1393,   3800,    525,  86046,  99055,    382,   1806,  52880,  18241,\n          10434,     25,    576,  18241,  36756,   5810,  22990,    304,  10434,\n            323,   1894,     11,  25377,  38432,  10876,    323,  20443,    382,\n            641,  78399,  17716,     25,    576,  17716,    374,  60337,    323,\n          80746,     11,    448,  21314,    323,  34512,  25377,  39140,    323,\n          70885,    382,  23356,  13595,  61590,     25,    576,   9864,    594,\n           4419,    525,  61136,    323,  70885,     11,   7945,    279,  27800,\n           4419,     11,    892,   6853,   6169,  48792,    382,   9286,  16488,\n           1894,  49743,     25,   9526,    525,  38432,  49485,     11,  31061,\n           5810,  41029,   1149,     88,    323,   5989,    367,     11,   7945,\n            304,    279,  18241,    382,     41,  96476,  12822,    323,  12955,\n            367,     25,   4329,   5671,  30224,  26742,   3556,  12822,    323,\n          12955,    367,     11,   5310,   2163,    279,  12822,    315,    279,\n           9864,    594,   2487,    382,   1806,   7951,   4532,  71734,     25,\n          66449,    323,  21314,    389,    279,  18241,    525,  74198,  22383,\n             11,  31061,    264,   5810,   2326,  32420,  11094,     13, 151645,\n            198, 151644,  77091,    198,   1806,   7951,   4532,   7912,  62751,\n             25,   1230,  52880,   7886,  58302,   3100,  62751,    304,   2176,\n           6414,     11,  22561,   7907,   5424,    382,   1918,   4668,  38413,\n            315,   5810,  29853,     25,  49840,   7952,  56799,  10876,    304,\n            279,   1909,   1290,     11,  31061,   5810,  10434,  22990,    382,\n           1806,   7951,   4532,  18241,  10434,     25,    576,  18241,  36756,\n           5810,  22990,    304,  10434,    323,   1894,     11,  25377,  38432,\n          10876,    323,  20443,    382,    641,  78399,  17716,     25,    576,\n          17716,    374,  60337,    323,  80746,     11,    448,  21314,    323,\n          34512,  25377,  39140,    323,  70885,    382,  23356,  13595,  61590,\n             25,    576,   9864,    594,   4419,    525,  61136,    323,  70885,\n             11,   7945,    279,  27800,   4419,     11,    892,   6853,   6169,\n          48792,    382,   9286,  16488,   1894,  49743,     25,   9526,    525,\n          38432,  49485,     11,  31061,   5810,  41029,   1149,     88,    323,\n           5989,    367,     11,   7945,    304,    279]], device='cuda:0')\nTrimming the generated IDs to exclude the input tokens...\nTrimmed generated IDs: [tensor([ 1806,  7951,  4532,  7912, 62751,    25,  1230, 52880,  7886, 58302,\n         3100, 62751,   304,  2176,  6414,    11, 22561,  7907,  5424,   382,\n         1918,  4668, 38413,   315,  5810, 29853,    25, 49840,  7952, 56799,\n        10876,   304,   279,  1909,  1290,    11, 31061,  5810, 10434, 22990,\n          382,  1806,  7951,  4532, 18241, 10434,    25,   576, 18241, 36756,\n         5810, 22990,   304, 10434,   323,  1894,    11, 25377, 38432, 10876,\n          323, 20443,   382,   641, 78399, 17716,    25,   576, 17716,   374,\n        60337,   323, 80746,    11,   448, 21314,   323, 34512, 25377, 39140,\n          323, 70885,   382, 23356, 13595, 61590,    25,   576,  9864,   594,\n         4419,   525, 61136,   323, 70885,    11,  7945,   279, 27800,  4419,\n           11,   892,  6853,  6169, 48792,   382,  9286, 16488,  1894, 49743,\n           25,  9526,   525, 38432, 49485,    11, 31061,  5810, 41029,  1149,\n           88,   323,  5989,   367,    11,  7945,   304,   279],\n       device='cuda:0')]\nDecoding the generated IDs to text...\nFinal output text:\n\n--- Output 1 ---\nUnrealistic eye reflections: Unnatural symmetrical light reflections in both eyes, suggesting generated elements.\n\nOver-smoothing of natural textures: Fur appears unusually smooth in the top right, lacking natural texture variation.\n\nUnrealistic fur texture: The fur lacks natural variation in texture and color, appearing overly smooth and artificial.\n\nInconsistent lighting: The lighting is uneven and unnatural, with highlights and shadows appearing inconsistent and unrealistic.\n\nDistorted anatomy: The animal's features are distorted and unrealistic, particularly the facial features, which lack proper proportions.\n\nArtificial color saturation: Colors are overly saturated, lacking natural subtlety and gradation, particularly in the\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"save_dir = \"/kaggle/working/model\"\n\n# Create the save directory\nos.makedirs(save_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:44:05.747928Z","iopub.execute_input":"2025-06-03T18:44:05.748379Z","iopub.status.idle":"2025-06-03T18:44:05.753086Z","shell.execute_reply.started":"2025-06-03T18:44:05.748354Z","shell.execute_reply":"2025-06-03T18:44:05.752143Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"print(\"Saving model to /kaggle/working/model ...\")\ntokenizer.save_pretrained(save_dir)\nprocessor.save_pretrained(save_dir)\nmodel.save_pretrained(save_dir)\nprint(\"✅ Done: Model saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:44:05.992849Z","iopub.execute_input":"2025-06-03T18:44:05.993204Z","iopub.status.idle":"2025-06-03T18:44:07.474946Z","shell.execute_reply.started":"2025-06-03T18:44:05.993172Z","shell.execute_reply":"2025-06-03T18:44:07.473983Z"}},"outputs":[{"name":"stdout","text":"Saving model to /kaggle/working/model ...\n✅ Done: Model saved.\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"import shutil\n\n# Zip the /kaggle/working/model folder into /kaggle/working/qwen_model.zip\nshutil.make_archive(\"/kaggle/working/qwen_model\", 'zip', \"/kaggle/working/model\")\n\nprint(\"✅ Model zipped as qwen_model.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:47:00.407541Z","iopub.execute_input":"2025-06-03T18:47:00.407953Z","iopub.status.idle":"2025-06-03T18:47:01.542535Z","shell.execute_reply.started":"2025-06-03T18:47:00.407923Z","shell.execute_reply":"2025-06-03T18:47:01.541530Z"}},"outputs":[{"name":"stdout","text":"✅ Model zipped as qwen_model.zip\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"import shutil\n\n# This will create a zip file at /kaggle/working/working_dir.zip\nshutil.make_archive(\"/kaggle/working/working_dir\", 'zip', \"/kaggle/working\")\n\nprint(\"✅ Entire /kaggle/working directory zipped as working_dir.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:56:25.153398Z","iopub.execute_input":"2025-06-03T18:56:25.153746Z","iopub.status.idle":"2025-06-03T18:58:50.214026Z","shell.execute_reply.started":"2025-06-03T18:56:25.153721Z","shell.execute_reply":"2025-06-03T18:58:50.212810Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1788\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mfdst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compressor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-fe7e7359f0ce>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# This will create a zip file at /kaggle/working/working_dir.zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/working_dir\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/kaggle/working\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Entire /kaggle/working directory zipped as working_dir.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msave_cwd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36m_make_zipfile\u001b[0;34m(base_name, base_dir, verbose, dry_run, logger, owner, group, root_dir)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                         \u001b[0marcname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marcdirpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m                         \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adding '%s'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1788\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1789\u001b[0m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zip64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mZIP64_LIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                         raise RuntimeError(\n\u001b[0m\u001b[1;32m   1174\u001b[0m                             'File size unexpectedly exceeded ZIP64 limit')\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mZIP64_LIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: File size unexpectedly exceeded ZIP64 limit"],"ename":"RuntimeError","evalue":"File size unexpectedly exceeded ZIP64 limit","output_type":"error"}],"execution_count":65},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}